# üìò H∆Ø·ªöNG D·∫™N CHI TI·∫æT - GI·∫¢I TH√çCH T·ª™NG D√íNG CODE

## üìã M·ª§C L·ª§C
1. [Gi·ªõi thi·ªáu](#gi·ªõi-thi·ªáu)
2. [Gi·∫£i th√≠ch Dockerfile](#gi·∫£i-th√≠ch-dockerfile)
3. [Gi·∫£i th√≠ch .dockerignore](#gi·∫£i-th√≠ch-dockerignore)
4. [Gi·∫£i th√≠ch seccomp-profile.json](#gi·∫£i-th√≠ch-seccomp-profile)
5. [Gi·∫£i th√≠ch apparmor-profile](#gi·∫£i-th√≠ch-apparmor-profile)
6. [Gi·∫£i th√≠ch kubernetes-security.yaml](#gi·∫£i-th√≠ch-kubernetes)
7. [Gi·∫£i th√≠ch docker-compose-security.yaml](#gi·∫£i-th√≠ch-docker-compose)
8. [Gi·∫£i th√≠ch Jenkinsfile - T·ª´ Zero ƒë·∫øn Advance](#gi·∫£i-th√≠ch-jenkinsfile)
9. [Gi·∫£i th√≠ch Terraform - T·ª´ Zero ƒë·∫øn Advance](#gi·∫£i-th√≠ch-terraform)

---

## üéØ GI·ªöI THI·ªÜU

### Docker l√† g√¨?
**Docker** l√† c√¥ng ngh·ªá **containerization** - ƒë√≥ng g√≥i ·ª©ng d·ª•ng c√πng t·∫•t c·∫£ dependencies th√†nh m·ªôt **container** c√≥ th·ªÉ ch·∫°y ·ªü b·∫•t c·ª© ƒë√¢u.

**V√≠ d·ª• d·ªÖ hi·ªÉu:**
```
Container = Nh√† di ƒë·ªông (nh√† ƒë√£ c√≥ s·∫µn ƒë·ªì ƒë·∫°c)
Image = B·∫£n v·∫Ω thi·∫øt k·∫ø nh√† di ƒë·ªông
Dockerfile = C√¥ng th·ª©c ƒë·ªÉ x√¢y nh√† di ƒë·ªông
```

---

## üìÑ GI·∫¢I TH√çCH DOCKERFILE

### D√íNG 1-12: PH·∫¶N ƒê·∫¶U - SYNTAX V√Ä CHU·∫®N

```dockerfile
# syntax=docker/dockerfile:1.7
```
**GI·∫¢I TH√çCH:**
- **# syntax=**: N√≥i v·ªõi Docker d√πng phi√™n b·∫£n Dockerfile syntax n√†o
- **docker/dockerfile:1.7**: D√πng BuildKit phi√™n b·∫£n 1.7 (phi√™n b·∫£n m·ªõi nh·∫•t 2025)
- **T·∫†I SAO C·∫¶N?** ƒê·ªÉ s·ª≠ d·ª•ng t√≠nh nƒÉng m·ªõi nh∆∞ `--mount`, cache, SSH mounts

```dockerfile
# =============================================================================
# ENTERPRISE-GRADE DOCKERFILE - ULTIMATE BEST PRACTICES (2025)
# =============================================================================
```
**GI·∫¢I TH√çCH:**
- Ch·ªâ l√† **comment** (ghi ch√∫)
- D√πng ƒë·ªÉ ng∆∞·ªùi ƒë·ªçc bi·∫øt file n√†y c√≥ ti√™u chu·∫©n cao nh·∫•t

```dockerfile
# Standards Compliance:
# - CIS Docker Benchmark 1.5.0
```
**GI·∫¢I TH√çCH:**
- **CIS Docker Benchmark**: B·ªô chu·∫©n b·∫£o m·∫≠t c·ªßa Docker (Center for Internet Security)
- Phi√™n b·∫£n 1.5.0 l√† b·ªô chu·∫©n m·ªõi nh·∫•t
- Quy ƒë·ªãnh kho·∫£ng 150 rules ƒë·ªÉ Docker container an to√†n

```dockerfile
# - OCI (Open Container Initiative) Runtime Specification
```
**GI·∫¢I TH√çCH:**
- **OCI**: T·ªï ch·ª©c qu·ªëc t·∫ø ƒë·ªãnh nghƒ©a chu·∫©n container
- Gi√∫p Docker images ch·∫°y ƒë∆∞·ª£c tr√™n nhi·ªÅu platform (Docker, Podman, Kubernetes)

```dockerfile
# - NIST Container Security Guidelines
```
**GI·∫¢I TH√çCH:**
- **NIST**: Vi·ªán ti√™u chu·∫©n k·ªπ thu·∫≠t qu·ªëc gia M·ªπ
- H∆∞·ªõng d·∫´n b·∫£o m·∫≠t container cho ch√≠nh ph·ªß M·ªπ

```dockerfile
# - DockerCon 2024 Best Practices
```
**GI·∫¢I TH√çCH:**
- H·ªôi ngh·ªã Docker l·ªõn nh·∫•t th·∫ø gi·ªõi
- Best practices ƒë∆∞·ª£c ƒë√∫c k·∫øt t·ª´ c√°c chuy√™n gia

```dockerfile
# - CTF Security Competition Standards
```
**GI·∫¢I TH√çCH:**
- **CTF = Capture The Flag**: Cu·ªôc thi hack thu·∫≠t to√°n to√†n c·∫ßu
- DEF CON CTF, Google CTF, HackTM
- Standards b·∫£o m·∫≠t t·ª´ c√°c cu·ªôc thi n√†y c·ª±c k·ª≥ kh·∫Øc nghi·ªát

```dockerfile
# - Supply Chain Levels for Software Artifacts (SLSA)
```
**GI·∫¢I TH√çCH:**
- **SLSA**: Chu·∫©n b·∫£o m·∫≠t chu·ªói cung ·ª©ng ph·∫ßn m·ªÅm c·ªßa Google
- NgƒÉn ch·∫∑n t·∫•n c√¥ng supply chain (nh∆∞ SolarWinds 2020)

---

### D√íNG 14-36: BUILD ARGUMENTS

```dockerfile
# ------------------------------------------
# BUILD ARGUMENTS (Front matter)
# ------------------------------------------
```
**GI·∫¢I TH√çCH:**
- **ARG**: Argument (ƒë·ªëi s·ªë) - bi·∫øn s·ªë d√πng KHI BUILD image
- Kh√°c v·ªõi **ENV** (bi·∫øn m√¥i tr∆∞·ªùng d√πng KHI RUN container)
- **Front matter**: ƒê·ªÉ ·ªü ƒë·∫ßu file (tr∆∞·ªõc FROM)

```dockerfile
# ‚úÖ Use ARGs for metadata (not secrets!)
```
**GI·∫¢I TH√çCH:**
- ARG d√πng cho metadata (th√¥ng tin m√¥ t·∫£)
- **KH√îNG BAO GI·ªú** d√πng ARG cho passwords, API keys
- V√¨ ARG s·∫Ω visible trong `docker history`

```dockerfile
# ‚úÖ Default values for local development
# ‚úÖ Override at build time: --build-arg VERSION=1.0.0
```
**GI·∫¢I TH√çCH:**
- Gi√° tr·ªã default d√πng khi dev local
- C√≥ th·ªÉ override khi build production:
```bash
docker build --build-arg VERSION=2.0.0 --build-arg NODE_VERSION=21 .
```

---

#### D√íNG 21-23: BASE IMAGE ARGUMENTS

```dockerfile
ARG NODE_VERSION=20
```
**GI·∫¢I TH√çCH:**
- T√™n bi·∫øn: `NODE_VERSION`
- Gi√° tr·ªã m·∫∑c ƒë·ªãnh: `20` (Node.js version 20 LTS)
- D√πng ƒë·ªÉ ch·ªçn version Node.js
- **Override** khi mu·ªën version kh√°c:
```bash
docker build --build-arg NODE_VERSION=18 .
```

```dockerfile
ARG ALPINE_VERSION=3.19
```
**GI·∫¢I TH√çCH:**
- **Alpine Linux**: Distro Linux si√™u nh·ªè (~5MB)
- Phi√™n b·∫£n 3.19 l√† stable version 2024
- Nh·ªè h∆°n Ubuntu 40 l·∫ßn

```dockerfile
ARG NODE_IMAGE_SHA256=abc123...
```
**GI·∫¢I TH√çCH:**
- **SHA256**: M√£ hash fingerprint c·ªßa image
- D√πng ƒë·ªÉ **verify image integrity** (kh√¥ng b·ªã b·ªãn change)
- Khi pull image, Docker s·∫Ω check hash n√†y
- N·∫øu hash kh√¥ng kh·ªõp ‚Üí s·∫Ω t·ª´ ch·ªëi ch·∫°y
- **C√°ch l·∫•y SHA256 th·ª±c t·∫ø:**
```bash
docker pull node:20-alpine
docker inspect node:20-alpine | grep RepoDigest
# K·∫øt qu·∫£: node:20-alpine@sha256:real_hash_here
```

---

#### D√íNG 25-32: METADATA ARGUMENTS

```dockerfile
# ‚úÖ Metadata labels (OCI compliant)
```
**GI·∫¢I TH√çCH:**
- **Metadata**: D·ªØ li·ªáu v·ªÅ d·ªØ li·ªáu (data about data)
- **OCI compliant**: Tu√¢n theo chu·∫©n OCI
- Labels s·∫Ω ƒë∆∞·ª£c embed v√†o Docker image

```dockerfile
ARG BUILD_DATE
```
**GI·∫¢I TH√çCH:**
- Ng√†y gi·ªù build image
- **Kh√¥ng c√≥ gi√° tr·ªã m·∫∑c ƒë·ªãnh** (b·∫Øt bu·ªôc ph·∫£i cung c·∫•p)
- **C√°ch set:**
```bash
docker build --build-arg BUILD_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ") .
```

```dockerfile
ARG VERSION=1.0.0
```
**GI·∫¢I TH√çCH:**
- Version c·ªßa ·ª©ng d·ª•ng
- D√πng ƒë·ªÉ track versions trong production
- Format chu·∫©n: **Semantic Versioning** (MAJOR.MINOR.PATCH)
  - **MAJOR**: Breaking changes (1.0.0 ‚Üí 2.0.0)
  - **MINOR**: New features (1.0.0 ‚Üí 1.1.0)
  - **PATCH**: Bug fixes (1.0.0 ‚Üí 1.0.1)

```dockerfile
ARG VCS_REF
```
**GI·∫¢I TH√çCH:**
- **VCS** = Version Control System (Git commit hash)
- D√πng ƒë·ªÉ bi·∫øt code n√†o ƒë√£ t·∫°o ra image n√†y
- **C√°ch set:**
```bash
docker build --build-arg VCS_REF=$(git rev-parse --short HEAD) .
# K·∫øt qu·∫£: a1b2c3d
```

```dockerfile
ARG VCS_URL=https://github.com/your-org/your-repo
```
**GI·∫¢I TH√çCH:**
- URL c·ªßa Git repository
- ƒê·ªÉ ng∆∞·ªùi kh√°c bi·∫øt source code ·ªü ƒë√¢u
- **Example th·ª±c t·∫ø:**
```bash
--build-arg VCS_URL=https://github.com/facebook/react
```

```dockerfile
ARG AUTHOR=devops@example.com
```
**GI·∫¢I TH√çCH:**
- Email ng∆∞·ªùi t·∫°o/image maintainer
- D√πng ƒë·ªÉ li√™n h·ªá khi c√≥ v·∫•n ƒë·ªÅ

```dockerfile
ARG DESCRIPTION="Production-ready Node.js application"
```
**GI·∫¢I TH√çCH:**
- M√¥ t·∫£ ng·∫Øn v·ªÅ image
- Gi√∫p ng∆∞·ªùi kh√°c hi·ªÉu image d√πng ƒë·ªÉ l√†m g√¨

```dockerfile
ARG LICENSE="MIT"
```
**GI·∫¢I TH√çCH:**
- License c·ªßa ph·∫ßn m·ªÅm
- C√°c license ph·ªï bi·∫øn:
  - **MIT**: R·∫•t tho√°ng,ÂïÜÁî® mi·ªÖn ph√≠
  - **Apache 2.0**: Gi·ªëng MIT nh∆∞ng c√≥ patent protection
  - **GPL**: Copyleft, ph·∫£i open source

---

#### D√íNG 34-36: REPRODUCIBLE BUILDS

```dockerfile
# ‚úÖ Reproducible builds (GNU/Reproducible-Builds standard)
```
**GI·∫¢I TH√çCH:**
- **Reproducible build**: Build l·∫°i t·ª´ c√πng source code ‚Üí ra image **IDENTICAL** (byte-by-byte)
- Quan tr·ªçng cho:
  - Security auditing
  - Compliance (SOC2, HIPAA)
  - Trust (bi·∫øt ch√≠nh x√°c code g√¨ ƒëang ch·∫°y)

```dockerfile
# ‚úÖ Set via: --build-arg SOURCE_DATE_EPOCH=$(git log -1 --format=%ct)
```
**GI·∫¢I TH√çCH:**
- **SOURCE_DATE_EPOCH**: Timestamp (Unix timestamp)
- D√πng ƒë·ªÉ set **modification time** c·ªßa files
- **$(git log -1 --format=%ct)**: L·∫•y timestamp c·ªßa commit cu·ªëi
- **V√≠ d·ª•:**
```bash
git log -1 --format=%ct
# K·∫øt qu·∫£: 1704067200 (Dec 31, 2023 00:00:00 GMT)
```

```dockerfile
ARG SOURCE_DATE_EPOCH
```
**GI·∫¢I TH√çCH:**
- Bi·∫øn ch·ª©a timestamp
- S·∫Ω ƒë∆∞·ª£c d√πng trong `ENV` v√† `npm ci`

---

### D√íNG 38-77: STAGE 0 - BASE IMAGE

```dockerfile
# ------------------------------------------
# STAGE 0: BASE IMAGE
# ------------------------------------------
```
**GI·∫¢I TH√çCH:**
- ƒê√¢y l√† **stage ƒë·∫ßu ti√™n** trong 7 stages
- M·ªói stage = 1 layer trong multi-stage build
- **T·∫°i sao nhi·ªÅu stages?**
  - Gi·∫£m image size (ch·ªâ l·∫•y nh·ªØng g√¨ c·∫ßn)
  - TƒÉng security (kh√¥ng bao g·ªìm build tools trong production)

```dockerfile
# ‚úÖ BuildKit syntax for latest features
# ‚úÖ Specific version with SHA256 digest
# ‚úÖ OCI annotations
```
**GI·∫¢I TH√çCH:**
- C√°c comment n√†y nh·∫Øc l·∫°i nh·ªØng best practices
- Will be explained below

---

#### D√íNG 45: FROM STATEMENT

```dockerfile
FROM node:${NODE_VERSION}-alpine${ALPINE_VERSION}@sha256:${NODE_IMAGE_SHA256} AS base
```

**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`FROM`**:
   - Keyword ƒë·ªÉ ch·ªçn base image
   - M·ªçi Dockerfile ƒë·ªÅu b·∫Øt ƒë·∫ßu v·ªõi FROM

2. **`node:`**:
   - T√™n image tr√™n Docker Hub
   - Official Node.js image

3. **`${NODE_VERSION}`**:
   - S·ª≠ d·ª•ng bi·∫øn ARG ƒë√£ÂÆö‰πâ ·ªü d√≤ng 21
   - Gi√° tr·ªã = `20` (n·∫øu kh√¥ng override)
   - **K·∫øt qu·∫£**: `node:20`

4. **`-alpine`**:
   - Suffix ƒë·ªÉ ch·ªçn variant Alpine Linux
   - Variant kh√°c: `-slim` (Debian slim), `-buster` (Debian 10)
   - **Size comparison**:
     - `node:20-alpine`: ~180MB
     - `node:20-slim`: ~250MB
     - `node:20`: ~900MB

5. **`${ALPINE_VERSION}`**:
   - Bi·∫øn ARG t·ª´ d√≤ng 22
   - Gi√° tr·ªã = `3.19`
   - **K·∫øt qu·∫£**: `node:20-alpine3.19`

6. **`@sha256:${NODE_IMAGE_SHA256}`**:
   - **Digest**: Fingerprint c·ªßa image
   - **@**: Syntax ƒë·ªÉ ch·ªâ ƒë·ªãnh digest
   - `${NODE_IMAGE_SHA256}`: Bi·∫øn t·ª´ d√≤ng 23
   - **T·∫°i sao c·∫ßn?**
     - **Security**: NgƒÉn ch·∫∑n fake/compromised images
     - **Reproducibility**: ƒê·∫£m b·∫£o pull ƒë√∫ng image
   - **V√≠ d·ª• th·ª±c t·∫ø:**
   ```dockerfile
   FROM node:20-alpine@sha256:a1b2c3d4e5f6...
   ```

7. **`AS base`**:
   - ƒê·∫∑t t√™n cho stage n√†y l√† `base`
   - D√πng ƒë·ªÉ reference ·ªü stages sau
   - **V√≠ d·ª•**:
   ```dockerfile
   COPY --from=base /app /app
   ```

**K·∫æT QU·∫¢ C·ª¶A D√íNG N√ÄY:**
```
Pull image: node:20-alpine3.19
Verify digest: sha256:abc123...
Stage name: base
```

---

#### D√íNG 47-54: C√ÄI ƒê·∫∂T PACKAGES

```dockerfile
# ‚úÖ Install dumb-init for proper signal handling (PID 1)
```
**GI·∫¢I TH√çCH:**
- **dumb-init**: M·ªôt tiny init system
- **PID 1**: Process ID 1 (process ƒë·∫ßu ti√™n trong container)
- **Signal handling**: X·ª≠ l√Ω t√≠n hi·ªáu (SIGTERM, SIGKILL)
- **T·∫°i sao c·∫ßn?**
  - Khi container stop, Docker g·ª≠i SIGTERM
  - N·∫øu kh√¥ng c√≥ init system ‚Üí signals kh√¥ng ƒë∆∞·ª£c forward correctly
  - Dumb-init fix v·∫•n ƒë·ªÅ n√†y

```dockerfile
# ‚úÖ Install security tools for runtime scanning
```
**GI·∫¢I TH√çCH:**
- C√°c c√¥ng c·ª• security s·∫Ω ƒë∆∞·ª£c c√†i
- D√πng ƒë·ªÉ scan vulnerabilities trong container

```dockerfile
RUN apk add --no-cache \
```
**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`RUN`**:
   - Execute command trong build time
   - K·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c commit v√†o layer

2. **`apk add`**:
   - **Alpine Package Keeper** - Package manager c·ªßa Alpine
   - T∆∞∆°ng t·ª± `apt` (Ubuntu), `yum` (CentOS)
   - D√πng ƒë·ªÉ c√†i packages

3. **`--no-cache`**:
   - Kh√¥ng cache index files
   - **T·∫°i sao?**
     - Gi·∫£m image size
     - Force use latest versions (security)
   - **Without --no-cache**:
     ```
     /var/cache/apk/packages: 50MB
     ```

4. **`\`**:
   - Line continuation character
   - Cho ph√©p command span multiple lines
   - TƒÉng readability

---

```dockerfile
    dumb-init \
```
**GI·∫¢I TH√çCH:**
- Package name
- D√πng ƒë·ªÉ handle signals properly

```dockerfile
    ca-certificates \
```
**GI·∫¢I TH√çCH:**
- **CA Certificates**: Ch·ª©ng ch·ªâ SSL/TLS
- C·∫ßn thi·∫øt ƒë·ªÉ g·ªçi HTTPS APIs
- V√≠ d·ª•: `fetch('https://api.example.com')`
- **Without this**:
  ```
  Error: unable to get local issuer certificate
  ```

```dockerfile
    tzdata \
```
**GI·∫¢I TH√çCH:**
- **Timezone data**: D·ªØ li·ªáu timezone
- C·∫ßn ƒë·ªÉ set timezone cho container
- V√≠ d·ª•: `TZ=Asia/Ho_Chi_Minh`

```dockerfile
    && rm -rf /var/cache/apk/* \
```
**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`&&`**:
   - Command separator
   - Ch·∫°y command ti·∫øp theo n·∫øu command tr∆∞·ªõc th√†nh c√¥ng
   - **Why use &&?**
     - N·∫øu `apk add` fail ‚Üí kh√¥ng execute `rm -rf`
     - Prevent partial/corrupted layers

2. **`rm -rf`**:
   - **rm**: Remove command
   - **-r**: Recursive (x√≥a folder)
   - **-f**: Force (kh√¥ng h·ªèi x√°c nh·∫≠n)

3. **`/var/cache/apk/*`**:
   - Cache directory c·ªßa apk
   - D·ªçn d·∫πp ƒë·ªÉ gi·∫£m image size
   - **Savings**: ~20-50MB

```dockerfile
    && rm -rf /tmp/*
```
**GI·∫¢I TH√çCH:**
- D·ªçn d·∫πp temporary files
- `/tmp`: Temporary directory
- Reduce attack surface (less files in container)

**T·ªîNG K·∫æT D√íNG 49-54:**
```
C√†i packages: dumb-init, ca-certificates, tzdata
D·ªçn cache: /var/cache/apk, /tmp
K·∫øt qu·∫£: Cleaner, smaller, more secure
```

---

#### D√íNG 56-66: OCI ANNOTATIONS

```dockerfile
# ‚úÖ OCI Annotations (OCI 1.1 specification)
```
**GI·∫¢I TH√çCH:**
- **OCI 1.1**: Phi√™n b·∫£n spec c·ªßa OCI
- **Annotations**: Metadata chu·∫©n h√≥a
- D√πng cho:
  - Image scanning tools
  - Container registries
  - Compliance reporting

```dockerfile
LABEL org.opencontainers.image.created="${BUILD_DATE}" \
```
**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`LABEL`**:
   - Th√™m metadata v√†o image
   - C√≥ th·ªÉ inspect v·ªõi: `docker inspect myimage`

2. **`org.opencontainers`**:
   - **Namespace**: Ti·ªÅn t·ªë chu·∫©n OCI
   - Tr√°nh xung ƒë·ªôt labels

3. **`.image.created`**:
   - **Key**: T√™n c·ªßa label
   - Ng√†y t·∫°o image
   - Format: ISO 8601 (2024-01-15T10:30:00Z)

4. **`"${BUILD_DATE}"`**:
   - **Value**: Gi√° tr·ªã c·ªßa label
   - D√πng bi·∫øn ARG t·ª´ d√≤ng 26
   - **V√≠ d·ª•**:
   ```dockerfile
   LABEL org.opencontainers.image.created="2024-01-15T10:30:00Z"
   ```

---

```dockerfile
      org.opencontainers.image.authors="${AUTHOR}" \
```
**GI·∫¢I TH√çCH:**
- **Key**: `org.opencontainers.image.authors`
- **Value**: Email ho·∫∑c t√™n t√°c gi·∫£
- **V√≠ d·ª•**:
```
org.opencontainers.image.authors="John Doe <john@example.com>"
```

```dockerfile
      org.opencontainers.image.description="${DESCRIPTION}" \
```
**GI·∫¢I TH√çCH:**
- M√¥ t·∫£ image
- D√πng trong UI ƒë·ªÉ hi·ªÉn th·ªã th√¥ng tin

```dockerfile
      org.opencontainers.image.licenses="${LICENSE}" \
```
**GI·∫¢I TH√çCH:**
- License c·ªßa image
- **SPDX License Identifier**:
  - `MIT`: MIT License
  - `Apache-2.0`: Apache License 2.0
  - `GPL-3.0`: GNU General Public License 3.0

```dockerfile
      org.opencontainers.image.revision="${VCS_REF}" \
```
**GI·∫¢I TH√çCH:**
- Git commit hash
- D√πng ƒë·ªÉ trace source code
- **V√≠ d·ª•**:
```
org.opencontainers.image.revision="a1b2c3d"
```

```dockerfile
      org.opencontainers.image.source="${VCS_URL}" \
```
**GI·∫¢I TH√çCH:**
- URL c·ªßa source code repository
- **V√≠ d·ª•**:
```
org.opencontainers.image.source="https://github.com/vercel/next.js"
```

```dockerfile
      org.opencontainers.image.title="myapp" \
```
**GI·∫¢I TH√çCH:**
- T√™n c·ªßa image/application
- Ng·∫Øn g·ªçn, d·ªÖ hi·ªÉu

```dockerfile
      org.opencontainers.image.version="${VERSION}" \
```
**GI·∫¢I TH√çCH:**
- Version c·ªßa application
- Format: SemVer (1.0.0, 2.1.3, etc.)

```dockerfile
      org.opencontainers.image.vendor="MyCompany" \
```
**GI·∫¢I TH√çCH:**
- T√™n c√¥ng ty/t·ªï ch·ª©c
- **V√≠ d·ª•**:
```
org.opencontainers.image.vendor="Google"
org.opencontainers.image.vendor="Facebook"
```

```dockerfile
      org.opencontainers.image.schema.version="1.0"
```
**GI·∫¢I TH√çCH:**
- Version c·ªßa OCI Image Spec
- Hardcoded `1.0` (current version)

**K·∫æT QU√Å KHI INSPECT:**
```json
{
  "Config": {
    "Labels": {
      "org.opencontainers.image.created": "2024-01-15T10:30:00Z",
      "org.opencontainers.image.version": "1.0.0",
      ...
    }
  }
}
```

---

#### D√íNG 68-71: ADDITIONAL LABELS

```dockerfile
# ‚úÖ Additional metadata labels
LABEL maintainer="${AUTHOR}" \
```
**GI·∫¢I TH√çCH:**
- **maintainer**: Custom label (kh√¥ng ph·∫£i OCI)
- Deprecated but still commonly used
- D√πng ƒë·ªÉ li√™n h·ªá maintainer

```dockerfile
      version="${VERSION}" \
```
**GI·∫¢I TH√çCH:**
- Simpler version label
- Non-namespaced (kh√¥ng c√≥ prefix)

```dockerfile
      description="${DESCRIPTION}"
```
**GI·∫¢I TH√çCH:**
- M√¥ t·∫£ ng·∫Øn
- Kh√°c v·ªõi OCI annotation v√¨ kh√¥ng c√≥ namespace

---

#### D√íNG 73-77: ENVIRONMENT VARIABLES

```dockerfile
# ‚úÖ Set default environment
ENV NODE_ENV=production \
```
**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`ENV`**:
   - Set environment variable
   - Available trong build time V√Ä runtime
   - Kh√°c v·ªõi ARG (ch·ªâ build time)

2. **`NODE_ENV=production`**:
   - **Key**: NODE_ENV
   - **Value**: production
   - **T√°c d·ª•ng**:
     - T·ªëi ∆∞u h√≥a Node.js (kh√¥ng load dev tools)
     - TƒÉng performance
     - Gi·∫£m memory usage

```dockerfile
    TZ=UTC \
```
**GI·∫¢I TH√çCH:**
- **TZ**: Timezone
- **UTC**: Coordinated Universal Time
- **T·∫°i sao UTC?**
  - Consistent across servers
  - Kh√¥ng c√≥ Daylight Saving Time issues
  - Best practice cho production

```dockerfile
    NODE_OPTIONS="--max-old-space-size=2048" \
```
**GI·∫¢I TH√çCH:**
- **NODE_OPTIONS**: Flags cho Node.js runtime
- **--max-old-space-size=2048**: Limit memory heap = 2GB
- **T·∫°i sao c·∫ßn?**
  - NgƒÉn container OOM (Out Of Memory)
  - Gi·∫£ d√πng: Container limit 512MB, Node.js heap = 2GB ‚Üí Crash
  - Best practice: Set heap < container limit
- **Calculation**:
  ```
  Container memory limit: 512MB
  Node.js heap: 512MB * 0.8 = ~400MB
  ```

```dockerfile
    SOURCE_DATE_EPOCH=${SOURCE_DATE_EPOCH}
```
**GI·∫¢I TH√çCH:**
- G√°n ARG v√†o ENV
- L√†m cho ARG available trong runtime
- D√πng cho reproducible builds

---

### D√íNG 79-100: STAGE 1 - DEPENDENCIES

```dockerfile
# ------------------------------------------
# STAGE 1: DEPENDENCIES (With BuildKit Cache)
# ------------------------------------------
```
**GI·∫¢I TH√çCH:**
- Stage th·ª© 2 trong 7 stages
- M·ª•c ti√™u: C√†i ƒë·∫∑t dependencies (npm packages)
- T√°ch ri√™ng ƒë·ªÉ **t·∫≠n d·ª•ng cache** (n·∫øu package.json kh√¥ng thay ƒë·ªïi ‚Üí kh√¥ng rebuild)

```dockerfile
FROM base AS dependencies
```
**GI·∫¢I TH√çCH:**
- **`FROM base`**: K·∫ø th·ª´a t·ª´ stage `base` (ƒë√£ defined ·ªü d√≤ng 45)
- **`AS dependencies`**: ƒê·∫∑t t√™n stage n√†y l√† `dependencies`
- K·∫øt qu·∫£: Stage n√†y c√≥ t·∫•t c·∫£ m·ªçi th·ª© t·ª´ `base` (dumb-init, ca-certificates, tzdata)

```dockerfile
WORKDIR /app
```
**GI·∫¢I TH√çCH:**
- **`WORKDIR`**: Set working directory
- **`/app`**: ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c
- **T√°c d·ª•ng**:
  - T·∫°o th∆∞ m·ª•c `/app` n·∫øu ch∆∞a c√≥
  - T·∫•t c·∫£ commands sau s·∫Ω ch·∫°y trong `/app`
  - T∆∞∆°ng t·ª± `cd /app` nh∆∞ng t·ªët h∆°n (t·ª± t·∫°o n·∫øu ch∆∞a c√≥)
- **Why `/app`?**
  - Convention chu·∫©n (c√≥ th·ªÉ d√πng `/usr/src/app` c≈©ng ƒë∆∞·ª£c)
  - Ng·∫Øn g·ªçn, d·ªÖ nh·ªõ

```dockerfile
# ‚úÖ Install build tools
RUN --mount=type=cache,target=/var/cache/apk \
```
**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`RUN`**: Execute command

2. **`--mount=type=cache`**:
   - **BuildKit feature** (c·∫ßn `# syntax=docker/dockerfile:1.7`)
   - **Cache mount**: Mount cache t·ª´ host v√†o container
   - **T√°c d·ª•ng**:
     - L∆∞u cache gi·ªØa c√°c builds
     - Speed up 5-10x
   - **Kh√¥ng c√≥ cache mount**:
     ```
     M·ªói l·∫ßn build: ~2 ph√∫t (download packages)
     ```
   - **C√≥ cache mount**:
     ```
     L·∫ßn ƒë·∫ßu: ~2 ph√∫t
     L·∫ßn 2+: ~10 gi√¢y (d√πng cache)
     ```

3. **`target=/var/cache/apk`**:
   - N∆°i cache ƒë∆∞·ª£c mount trong container
   - `/var/cache/apk`: Cache directory c·ªßa Alpine package manager

```dockerfile
    apk add --no-cache \
```
**GI·∫¢I TH√çCH:**
- C√†i packages cho Alpine

```dockerfile
        python3 \
```
**GI·∫¢I TH√çCH:**
- **Python 3**: Node.js native modules c·∫ßn Python ƒë·ªÉ build
- **V√≠ d·ª• native modules**:
  - `node-sass` (CSS preprocessor)
  - `bcrypt` (password hashing)
  - `sharp` (image processing)
- **Why c·∫ßn?** Nhi·ªÅu npm packages vi·∫øt b·∫±ng C++ ‚Üí c·∫ßn compile

```dockerfile
        make \
```
**GI·∫¢I TH√çCH:**
- **Make**: Build automation tool
- D√πng ƒë·ªÉ compile native modules

```dockerfile
        g++ \
```
**GI·∫¢I TH√çCH:**
- **G++**: GNU C++ compiler
- D√πng ƒë·ªÉ compile C++ code ‚Üí JavaScript bindings

```dockerfile
        pkgconfig \
```
**GI·∫¢I TH√çCH:**
- **pkg-config**: Tool ƒë·ªÉ l·∫•y th√¥ng tin v·ªÅ installed libraries
- Native modules c·∫ßn ƒë·ªÉ find dependencies

```dockerfile
    && rm -rf /var/cache/apk/*
```
**GI·∫¢I TH√çCH:**
- X√≥a cache trong container (KH√îNG x√≥a cache mount)
- Cache mount v·∫´n ƒë∆∞·ª£c l∆∞u ·ªü host
- Gi·∫£m image size

---

```dockerfile
# ‚úÖ Copy package files
COPY --link package*.json ./
```
**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`COPY`**: Copy files t·ª´ host v√†o container

2. **`--link`**:
   - **BuildKit feature**
   - **T√°c d·ª•ng**:
     - Fast copy (hardlinks thay v√¨ copy)
     - Share layers between builds
     - Reduce disk space
   - **T·ªëc ƒë·ªô**:
     ```
     Without --link: ~5 gi√¢y
     With --link: ~0.5 gi√¢y
     ```

3. **`package*.json`**:
   - **`*`**: Wildcard (match b·∫•t k·ª≥ k√Ω t·ª± n√†o)
   - **Matches**:
     - `package.json`
     - `package-lock.json`
   - **Why c·∫£ 2?**
     - `package.json`: Dependencies list
     - `package-lock.json`: Exact versions (reproducible builds)

4. **`./`**:
   - Destination (n∆°i copy ƒë·∫øn)
   - `./` = current directory = `/app` (working directory)

**T·∫†I SAO COPY package.json TR∆Ø·ªöC SOURCE CODE?**
```
‚úÖ ƒê√öNG:
1. Copy package.json
2. RUN npm install
3. Copy source code

‚ùå SAI:
1. Copy source code
2. Copy package.json
3. RUN npm install
```
**L√Ω do:**
- Source code thay ƒë·ªïi th∆∞·ªùng xuy√™n ‚Üí Docker cache invalidation
- package.json thay ƒë·ªïi √≠t ‚Üí Docker cache hit
- **V√≠ d·ª•**:
  ```
  ƒê·ªïi 1 d√≤ng code ‚Üí Cache invalidation ‚Üí npm install l·∫°i (ph√≠ 2 ph√∫t)
  Copy package.json tr∆∞·ªõc ‚Üí Ch·ªâ cache invalidation khi ƒë·ªïi dependencies
  ```

---

```dockerfile
# ‚úÖ BuildKit cache mount for npm (5x faster rebuilds)
RUN --mount=type=cache,target=/root/.npm \
```
**GI·∫¢I TH√çCH:**
- T∆∞∆°ng t·ª± apk cache mount
- Cache cho npm packages
- **Location**:
  ```
  /root/.npm: npm cache directory
  ```

```dockerfile
    --mount=type=bind,source=package.json,target=package.json \
```
**GI·∫¢I TH√çCH:**
- **bind mount**: Mount file t·ª´ host v√†o container
- **source=package.json**: File tr√™n host
- **target=package.json**: File trong container
- **Why?**
  - Ensure npm reads latest package.json
  - Consistency check

```dockerfile
    npm ci --only=production && \
```
**GI·∫¢I TH√çCH T·ª™NG PH·∫¶N:**

1. **`npm ci`**:
   - **ci** = Clean Install
   - **Kh√°c `npm install`**:
     ```
     npm install:
       - T·∫°o m·ªõi package-lock.json n·∫øu ch∆∞a c√≥
       - C·∫≠p nh·∫≠t package-lock.json
       - Kh√¥ng deterministic

     npm ci:
       - KH√îNG modify package-lock.json
       - X√≥a node_modules tr∆∞·ªõc khi install
       - Deterministic (c√πng input ‚Üí c√πng output)
       - Faster (kh√¥ng check versions)
     ```
   - **Why `npm ci`?**
     - Reproducible builds
     - CI/CD best practice
     - Predictable

2. **`--only=production`**:
   - Ch·ªâ install production dependencies
   - B·ªè qua devDependencies (jest, eslint, etc.)
   - **T√°c d·ª•ng**:
     ```
     All dependencies: 500MB
     Only production: 300MB
     Savings: 200MB (40%)
     ```

3. **`&&`**:
   - Chain commands
   - Ch·∫°y command ti·∫øp theo n·∫øu command tr∆∞·ªõc th√†nh c√¥ng

```dockerfile
    npm cache clean --force
```
**GI·∫¢I TH√çCH:**
- X√≥a npm cache
- **`--force`**: Bypass confirmation prompts
- **Why?**
  - Gi·∫£m image size (~50-100MB)
  - Cache ƒë√£ l∆∞u ·ªü cache mount r·ªìi

---

### D√íNG 101-127: STAGE 2 - DEVELOPMENT

```dockerfile
# ------------------------------------------
# STAGE 2: DEVELOPMENT (Optional)
# ------------------------------------------
```
**GI·∫¢I TH√çCH:**
- Stage d√πng cho local development
- **Optional**: Kh√¥ng b·∫Øt bu·ªôc

```dockerfile
FROM base AS development
```
**GI·∫¢I TH√çCH:**
- Start t·ª´ `base` stage
- ƒê·∫∑t t√™n l√† `development`

```dockerfile
WORKDIR /app
```
**GI·∫¢I TH√çCH:**
- Set working directory (same as before)

```dockerfile
# Install all dependencies (including dev)
COPY --link package*.json ./
```
**GI·∫¢I TH√çCH:**
- Copy package files
- **Note**: Kh√¥ng c√≥ `--only=production` ‚Üí install ALL

```dockerfile
RUN --mount=type=cache,target=/root/.npm \
    npm ci
```
**GI·∫¢I TH√çCH:**
- Install t·∫•t c·∫£ dependencies (including devDependencies)
- Bao g·ªìm: jest, eslint, prettier, typescript, etc.

```dockerfile
# Copy source code
COPY --link . .
```
**GI·∫¢I TH√çCH:**
- Copy t·∫•t c·∫£ source code
- **`.`** (first): Current directory on host
- **`.`** (second): Current directory in container (`/app`)
- **Includes**:
  - `src/`
  - `public/`
  - `next.config.js`
  - etc.

```dockerfile
# ‚úÖ Create non-root user
RUN addgroup -g 1001 -S nodejs && \
```
**GI·∫¢I TH√çCH:**
- **`addgroup`**: Create user group (Alpine command)
- **`-g 1001`**: Group ID = 1001
  - **Why 1001?**
    - 0 = root (avoid)
    - 1-999 = system users (avoid)
    - 1000+ = regular users (good)
- **`-S`**: Create system group
- **`nodejs`**: Group name

```dockerfile
    adduser -S nextjs -u 1001 -G nodejs
```
**GI·∫¢I TH√çCH:**
- **`adduser`**: Create user (Alpine command)
- **`-S`**: Create system user
- **`nextjs`**: Username
- **`-u 1001`**: User ID = 1001
- **`-G nodejs`**: Add to `nodejs` group

```dockerfile
USER nextjs
```
**GI·∫¢I TH√çCH:**
- Switch to non-root user
- **CRITICAL for security**
- All commands sau s·∫Ω ch·∫°y as `nextjs` user

```dockerfile
EXPOSE 3000
```
**GI·∫¢I TH√çCH:**
- **`EXPOSE`**: Document which port the container listens on
- **`3000`**: Port number
- **Note**: KH√îNG th·ª±c t·∫ø publish port
- Ch·ªâ l√† **documentation** - useful for:
  - `docker run -P` (auto publish all EXPOSEd ports)
  - Docker Compose (auto link containers)
  - Documentation purpose

```dockerfile
# ‚úÖ Use dumb-init for signal handling
ENTRYPOINT ["dumb-init", "--"]
```
**GI·∫¢I TH√çCH:**
- **`ENTRYPOINT`**: Command ƒë∆∞·ª£c ch·∫°y khi container starts
- **`["dumb-init", "--"]`**:
  - **Array form** (preferred)
  - `dumb-init`: Init system
  - `--`: End of options
- **T√°c d·ª•ng**:
  - Handle SIGTERM properly
  - Reap zombie processes

```dockerfile
CMD ["npm", "run", "dev"]
```
**GI·∫¢I TH√çCH:**
- **`CMD`**: Default command
- **`npm run dev`**: Run dev server
- **Note**: CMD c√≥ th·ªÉ override:
  ```bash
  docker run myapp npm run test
  ```

---

### D√íNG 129-163: STAGE 3 - BUILDER

```dockerfile
# ------------------------------------------
# STAGE 3: BUILDER (Production Build)
# ------------------------------------------
```
**GI·∫¢I TH√çCH:**
- Stage ƒë·ªÉ build ·ª©ng d·ª•ng (Next.js build, webpack, etc.)

```dockerfile
FROM base AS builder
```
**GI·∫¢I TH√çCH:**
- Start t·ª´ `base`
- ƒê·∫∑t t√™n `builder`

```dockerfile
WORKDIR /app
```

```dockerfile
# Copy dependencies
COPY --from=dependencies --link /app/node_modules ./node_modules
```
**GI·∫¢I TH√çCH:**
- **`--from=dependencies`**: Copy t·ª´ stage `dependencies`
- **Benefits**:
  - Kh√¥ng c·∫ßn reinstall l·∫°i
  - Faster builds
  - Smaller layers

```dockerfile
COPY --link . .
```
**GI·∫¢I TH√çCH:**
- Copy source code

```dockerfile
# ‚úÖ Build with metadata
ARG VERSION
```
**GI·∫¢I TH√çCH:**
- **ARG** c√≥ scope l√† stage
- C·∫ßn redefine l·∫°i ƒë·ªÉ d√πng trong stage n√†y

```dockerfile
ARG BUILD_DATE
ARG VCS_REF
```

```dockerfile
RUN --mount=type=cache,target=/root/.npm \
    --mount=type=cache,target=/app/.next/cache \
```
**GI·∫¢I TH√çCH:**
- 2 cache mounts:
  1. `/root/.npm`: npm cache
  2. `/app/.next/cache`: Next.js build cache

```dockerfile
    npm run build
```
**GI·∫¢I TH√çCH:**
- Run build script
- Next.js: Build production-optimized files
- Output: `.next/` directory

```dockerfile
# ‚úÖ Generate SBOM (Software Bill of Materials)
RUN --mount=type=cache,target=/root/.npm \
```

```dockerfile
    npm install -g @cyclonedx/cyclonedx-npm && \
```
**GI·∫¢I TH√çCH:**
- Install CycloneDX tool
- **CycloneDX**: SBOM standard
- **SBOM**: Danh s√°ch t·∫•t c·∫£ dependencies + versions + licenses

```dockerfile
    cyclonedx-npm --output-format json --output-file sbom.json && \
```
**GI·∫¢I TH√çCH:**
- Generate SBOM in JSON format

```dockerfile
    cyclonedx-npm --output-format xml --output-file sbom.xml
```
**GI·∫¢I TH√çCH:**
- Generate SBOM in XML format (c·∫£ 2 formats)

```dockerfile
# ‚úÖ Copy SBOM to final image
RUN mkdir -p /app/public && \
    mv sbom.json sbom.xml /app/public/
```
**GI·∫¢I TH√çCH:**
- Move SBOM files to public directory
- Serve via HTTP for compliance auditing

```dockerfile
# ‚úÖ Remove dev dependencies
RUN npm prune --production && \
```
**GI·∫¢I TH√çCH:**
- **`npm prune`**: Remove unused packages
- **`--production`**: Keep only production dependencies
- **Savings**: ~200MB

```dockerfile
    npm cache clean --force
```
**GI·∫¢I TH√çCH:**
- Clean npm cache

---

### D√íNG 165-186: STAGE 4 - SECURITY SCAN

```dockerfile
# ------------------------------------------
# STAGE 4: SECURITY SCANNER (Inline)
# ------------------------------------------
# ‚úÖ Run vulnerability scanner during build
# ‚úÖ Fails build if critical vulnerabilities found
```
**GI·∫¢I TH√çCH:**
- **Inline security scanning**: Qu√©t l·ªó h·ªïng trong build time
- N·∫øu c√≥ critical vulnerabilities ‚Üí Build FAIL

```dockerfile
FROM base AS security-scan
```
**GI·∫¢I TH√çCH:**
- Stage ri√™ng cho security scanning

```dockerfile
WORKDIR /app
```

```dockerfile
# Install Trivy scanner
RUN --mount=type=cache,target=/var/cache/apk \
    apk add --no-cache wget && \
```
**GI·∫¢I TH√çCH:**
- Install wget

```dockerfile
    wget -qO - https://aquasecurity.github.io/trivy-repo/debian/public.key | \
```
**GI·∫¢I TH√çCH:**
- Download Trivy GPG key

```dockerfile
    apk add --no-cache trivy
```
**GI·∫¢I TH√çCH:**
- Install Trivy scanner
- **Trivy**: Vulnerability scanner by Aqua Security

```dockerfile
# Copy built application
COPY --from=builder --link /app /app
```
**GI·∫¢I TH√çCH:**
- Copy t·ª´ `builder` stage

```dockerfile
# ‚úÖ Scan for vulnerabilities (FAIL on CRITICAL)
RUN trivy filesystem --no-progress --severity CRITICAL,HIGH --exit-code 1 /app || \
```
**GI·∫¢I TH√çCH:**
- **`trivy filesystem`**: Scan filesystem
- **`--no-progress`**: Kh√¥ng show progress bar
- **`--severity CRITICAL,HIGH`**: Ch·ªâ report critical/high severity
- **`--exit-code 1`**: Return exit code 1 n·∫øu c√≥ vulnerabilities
- **`|| ...`**: Fallback error message

```dockerfile
    (echo "Security scan failed! Fix critical vulnerabilities before deploying." && exit 1)
```
**GI·∫¢I TH√çCH:**
- Error message n·∫øu scan fail
- Exit v·ªõi code 1 ‚Üí Build fail

---

### D√íNG 188-268: STAGE 5 - PRODUCTION

```dockerfile
# ------------------------------------------
# STAGE 5: PRODUCTION (Minimal Runtime)
# ------------------------------------------
```
**GI·∫¢I TH√çCH:**
- **FINAL IMAGE** - ƒê√¢y l√† image d√πng cho production
- Minimal, secure, optimized

```dockerfile
FROM base AS production
```
**GI·∫¢I TH√çCH:**
- Start t·ª´ `base`
- ƒê·∫∑t t√™n `production`

```dockerfile
# ‚úÖ Security: Create non-root user BEFORE copying files
RUN addgroup -g 1001 -S nodejs && \
    adduser -S nextjs -u 1001 -G nodejs
```
**GI·∫¢I TH√çCH:**
- Create non-root user FIRST
- Why before? File permissions s·∫Ω ƒë∆∞·ª£c set correctly

```dockerfile
WORKDIR /app
```

```dockerfile
# ‚úÖ Copy built artifacts from builder
COPY --from=builder --chown=nextjs:nodejs --link \
```
**GI·∫¢I TH√çCH:**
- **`--from=builder`**: Copy t·ª´ builder stage
- **`--chown=nextjs:nodejs`**: Change owner to nextjs user
- **`--link`**: Fast copy (hardlinks)

```dockerfile
    /app/.next ./.next
```
**GI·∫¢I TH√çCH:**
- Copy Next.js build output
- `.next/`: Build artifacts

```dockerfile
COPY --from=builder --chown=nextjs:nodejs --link \
    /app/node_modules ./node_modules
```
**GI·∫¢I TH√çCH:**
- Copy production dependencies

```dockerfile
COPY --from=builder --chown=nextjs:nodejs --link \
    /app/package.json ./package.json
```
**GI·∫¢I TH√çCH:**
- Copy package.json

```dockerfile
COPY --from=builder --chown=nextjs:nodejs --link \
    /app/public ./public
```
**GI·∫¢I TH√çCH:**
- Copy public files (HTML, images, etc.)

```dockerfile
# ‚úÖ Copy SBOM for compliance
COPY --from=builder --chown=nextjs:nodejs --link \
    /app/public/sbom*.json ./public/
```
**GI·∫¢I TH√çCH:**
- Copy SBOM files
- For compliance auditing

```dockerfile
COPY --from=builder --chown=nextjs:nodejs --link \
    /app/public/sbom*.xml ./public/
```

```dockerfile
# ‚úÖ Create necessary directories with proper permissions
RUN mkdir -p /app/.next/cache && \
```
**GI·∫¢I TH√çCH:**
- Create cache directory

```dockerfile
    chown -R nextjs:nodejs /app/.next && \
```
**GI·∫¢I TH√çCH:**
- Recursive chown

```dockerfile
    chmod -R 755 /app
```
**GI·∫¢I TH√çCH:**
- **`chmod 755`**: Set permissions
  - **7 (rwx)**: Owner (read, write, execute)
  - **5 (r-x)**: Group & others (read, execute only)
- **Why 755?**
  - Files readable
  - Directories enterable
  - NOT writable by others (security)

```dockerfile
# ‚úÖ Switch to non-root user (CIS Benchmark 5.1)
USER nextjs
```
**GI·∫¢I TH√çCH:**
- Switch to non-root user
- **CRITICAL**: Container runs as non-root
- **Why?**
  - N·∫øu container compromised ‚Üí attacker kh√¥ng c√≥ root access
  - **CIS Benchmark 5.1**: Containers must run as non-root

```dockerfile
# ‚úÖ Production environment
ENV NODE_ENV=production \
```
**GI·∫¢I TH√çCH:**
- Override NODE_ENV (ensure production)

```dockerfile
    PORT=3000 \
```
**GI·∫¢I TH√çCH:**
- Default port

```dockerfile
    HOSTNAME="0.0.0.0" \
```
**GI·∫¢I TH√çCH:**
- Listen on all interfaces
- **Why 0.0.0.0?**
  - Container c·∫ßn accept connections t·ª´ outside
  - **127.0.0.1**: Ch·ªâ local
  - **0.0.0.0**: All interfaces (external reachable)

```dockerfile
    NODE_OPTIONS="--max-old-space-size=2048"
```
**GI·∫¢I TH√çCH:**
- Memory limit (nh∆∞ ƒë√£ gi·∫£i th√≠ch)

```dockerfile
# ‚úÖ STOPSIGNAL for graceful shutdown (CIS Benchmark 5.26)
# ‚úÖ SIGTERM (15) allows cleanup, SIGKILL (9) is immediate force-kill
STOPSIGNAL SIGTERM
```
**GI·∫¢I TH√çCH:**
- **`STOPSIGNAL`**: Signal Docker sends khi container stop
- **`SIGTERM`**: Termination signal (15)
  - Cho ph√©p app cleanup
  - Close connections gracefully
  - Save state
- **SIGKILL (9)**:
  - Force kill
  - Kh√¥ng cleanup
  - **BAD for production** (data loss, connection errors)
- **CIS Benchmark 5.26**: Must use SIGTERM

```dockerfile
# ‚úÖ Expose port (documentation only)
EXPOSE 3000
```
**GI·∫¢I TH√çCH:**
- Documentation (nh∆∞ ƒë√£ gi·∫£i th√≠ch)

```dockerfile
# ‚úÖ Health Check (CIS Benchmark 5.25)
HEALTHCHECK --interval=30s \
```
**GI·∫¢I TH√çCH:**
- **`HEALTHCHECK`**: ƒê·ªãnh nghƒ©a health check command
- **`--interval=30s`**: Run health check m·ªói 30s

```dockerfile
            --timeout=5s \
```
**GI·∫¢I TH√çCH:**
- Timeout sau 5s n·∫øu kh√¥ng response

```dockerfile
            --start-period=10s \
```
**GI·∫¢I TH√çCH:**
- **Start period**: 10s ƒë·∫ßu ti√™n kh√¥ng count failures
- Cho ph√©p app startup time

```dockerfile
            --retries=3 \
```
**GI·∫¢I TH√çCH:**
- Fail sau 3 consecutive failures

```dockerfile
    CMD node -e "
```
**GI·∫¢I TH√çCH:**
- **`node -e`**: Execute JavaScript code
- Inline health check script

```dockerfile
    const http = require('http');
```
**GI·∫¢I TH√çCH:**
- Import HTTP module

```dockerfile
    const options = {
      host: 'localhost',
      port: 3000,
      path: '/api/health',
      timeout: 2000
```
**GI·∫¢I TH√çCH:**
- Request options

```dockerfile
    };
```

```dockerfile
    const request = http.request(options, (res) => {
      process.exit(res.statusCode === 200 ? 0 : 1);
```
**GI·∫¢I TH√çCH:**
- Exit 0 (success) n·∫øu 200 OK
- Exit 1 (fail) n·∫øu kh√¥ng

```dockerfile
    });
```

```dockerfile
    request.on('error', () => process.exit(1));
```
**GI·∫¢I TH√çCH:**
- Exit 1 n·∫øu connection error

```dockerfile
    request.end();
    "
```
**GI·∫¢I TH√çCH:**
- End of script

```dockerfile
# ‚úÖ Use dumb-init for proper signal handling (SIGTERM, SIGCHLD)
# ‚úÖ Graceful shutdown with zero downtime
ENTRYPOINT ["dumb-init", "--"]
```
**GI·∫¢I TH√çCH:**
- Use dumb-init as PID 1
- Proper signal handling

```dockerfile
# ‚úÖ Start application
CMD ["node", ".next/standalone/server.js"]
```
**GI·∫¢I TH√çCH:**
- Start Next.js standalone server
- **Array form** (no shell parsing)

---

### D√íNG 270-356: STAGE 6 & 7 - DISTROLESS & CHAINGUARD

**GI·∫¢I TH√çCH NG·∫ÆN G·ªåN:**
- **Stage 6 (distroless)**: Google's minimal image - NO shell, NO package manager
- **Stage 7 (chainguard)**: Wolfi-based hardened image - Zero CVEs
- **Purpose**: Maximum security alternatives

---

## üìÑ GI·∫¢I TH√çCH .DOCKERIGNORE

**File n√†y d√πng ƒë·ªÉ lo·∫°i b·ªè files kh·ªèi Docker build context**

**V√≠ d·ª•**:
```
ƒê·∫æM S·ªê FILES TRONG CONTEXT:
- Kh√¥ng c√≥ .dockerignore: 50,000 files (node_modules)
- C√≥ .dockerignore: 100 files (ch·ªâ source code)

BUILD TIME:
- Kh√¥ng c√≥: ~3 ph√∫t (upload 50,000 files)
- C√≥: ~5 gi√¢y (upload 100 files)
```

**M·ªñI CATEGORY TRONG FILE:**

### Dependencies
```
node_modules
```
**GI·∫¢I TH√çCH:**
- Kh√¥ng bao gi·ªù copy node_modules v√†o image
- Why? Node_modules s·∫Ω ƒë∆∞·ª£c install l·∫°i trong container (via `npm ci`)
- Size: ~500MB

### Environment Files
```
.env
.env*.local
```
**GI·∫¢I TH√çCH:**
- **SECURITY RISK!** - Ch·ª©a secrets
- Kh√¥ng bao gi·ªù commit secrets v√†o image
- Secrets ph·∫£i ƒë∆∞·ª£c pass via environment variables t·∫°i runtime

### IDE Files
```
.vscode
.idea
```
**GI·∫¢I TH√çCH:**
- IDE configs
- Kh√¥ng c·∫ßn trong container
- Size: ~10MB

### Build Outputs
```
.next
dist
```
**GI·∫¢I TH√çCH:**
- Build artifacts
- S·∫Ω ƒë∆∞·ª£c generated trong container
- Don't copy t·ª´ host

---

## üîí GI·∫¢I TH√çCH SECCOMP PROFILE

**Seccomp** = **SEC**ure **COMP**uting Mode - Filter system calls

**V√ç D·ª§ D·ªÑ HI·ªÇU:**
```
System call = L·ªùi g·ªçi ƒë·∫øn kernel (h·ªá ƒëi·ªÅu h√†nh)
V√≠ d·ª•:
- open() ‚Üí M·ªü file
- read() ‚Üí ƒê·ªçc file
- write() ‚Üí Ghi file
- reboot() ‚Üí Restart m√°y
```

**SECCOMP L√ÄM G√å?**
- Allow: Ch·ªâ cho ph√©p 90 syscalls c·∫ßn thi·∫øt
- Block: Ch·∫∑n 60+ syscalls nguy hi·ªÉm

**V√ç D·ª§ SYSCALLS ƒê√É CH·∫∂N:**
```json
"reboot"  ‚Üí Kh√¥ng th·ªÉ restart m√°y t·ª´ trong container
"mount"   ‚Üí Kh√¥ng th·ªÉ mount filesystem
"ptrace"  ‚Üí Kh√¥ng th·ªÉ debug c√°c process kh√°c
```

**T·∫†I SAO C·∫¶N?**
- Gi·∫£m attack surface
- N·∫øu attacker compromise app ‚Üí ch·ªâ c√≥ th·ªÉ g·ªçi 90 syscalls (thay v√¨ 300+)
- **CIS Benchmark 5.24**: Container security requirement

---

## üõ°Ô∏è GI·∫¢I TH√çCH APPARMOR PROFILE

**AppArmor** = **Mandatory Access Control** (MAC)

**V√ç D·ª§ D·ªÑ HI·ªÇU:**
```
AppArmor = B·∫£o v·ªá t·∫°i filesystem level
- Ch·ªâ ƒë∆∞·ª£c ƒë·ªçc file A
- KH√îNG ƒë∆∞·ª£c ƒë·ªçc file B
- KH√îNG ƒë∆∞·ª£c write v√†o /etc
```

**KEY RULES TRONG PROFILE:**

### Allow Rules
```
/app/** r  ‚Üí ƒê∆∞·ª£c ƒë·ªçc t·∫•t c·∫£ files trong /app
```
**GI·∫¢I TH√çCH:**
- **r** = read (ƒë·ªçc)
- App c·∫ßn ƒë·ªçc source code

### Deny Rules
```
deny /bin/** ix  ‚Üí KH√îNG ƒë∆∞·ª£c execute shell
```
**GI·∫¢I TH√çCH:**
- **ix** = execute + inherit
- N·∫øu attacker compromise app ‚Üí kh√¥ng th·ªÉ spawn shell

### Network Rules
```
network inet stream  ‚Üí Cho ph√©p TCP connections
```
**GI·∫¢I TH√çCH:**
- App c·∫ßn connect ƒë·∫øn database, APIs

---

## ‚ò∏Ô∏è GI·∫¢I TH√çCH KUBERNETES SECURITY.YAML

**Kubernetes** = Container orchestration platform

**KEY COMPONENTS:**

### 1. Deployment
```yaml
replicas: 3
```
**GI·∫¢I TH√çCH:**
- Run 3 copies c·ªßa app
- High availability

### 2. Security Context
```yaml
runAsNonRoot: true
runAsUser: 1001
```
**GI·∫¢I TH√çCH:**
- Pod runs as non-root user
- User ID 1001

### 3. Resource Limits
```yaml
resources:
  limits:
    memory: "512Mi"
    cpu: "500m"
```
**GI·∫¢I TH√çCH:**
- Max memory: 512MB
- Max CPU: 0.5 cores (500 millicores)
- **Why?** Prevent runaway containers from consuming all resources

### 4. Health Probes
```yaml
livenessProbe:
  httpGet:
    path: /api/health
```
**GI·∫¢I TH√çCH:**
- **Liveness**: Check if app is alive
- **Readiness**: Check if app ready to receive traffic
- Kubernetes s·∫Ω restart pod n·∫øu liveness fail

### 5. Network Policy
```yaml
networkPolicy:
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
```
**GI·∫¢I TH√çCH:**
- **Firewall at pod level**
- Ch·ªâ accept traffic t·ª´ ingress controller
- Block direct traffic

---

## üê≥ GI·∫¢I TH√çCH DOCKER-COMPOSE-SECURITY.YAML

**Docker Compose** = Tool ƒë·ªÉ run multiple containers

**KEY SECURITY SETTINGS:**

### 1. Security Options
```yaml
security_opt:
  - no-new-privileges:true
```
**GI·∫¢I TH√çCH:**
- **no-new-privileges**: Container kh√¥ng th·ªÉ gain new privileges
- Prevent privilege escalation attacks

### 2. Read-Only Filesystem
```yaml
read_only: true
```
**GI·∫¢I TH√çCH:**
- Filesystem read-only
- N·∫øu attacker compromise ‚Üí kh√¥ng th·ªÉ write malware
- Exception: `/tmp` (writable tmpfs mount)

### 3. Capabilities
```yaml
cap_drop:
  - ALL
cap_add:
  - NET_BIND_SERVICE
```
**GI·∫¢I TH√çCH:**
- **cap_drop ALL**: Drop ALL Linux capabilities
- **cap_add NET_BIND_SERVICE**: Add back ONLY needed capability
- **NET_BIND_SERVICE**: Allow binding to port < 1024

### 4. Resource Limits
```yaml
deploy:
  resources:
    limits:
      cpus: "0.5"
      memory: 512M
```
**GI·∫¢I TH√çCH:**
- CPU: 0.5 cores
- Memory: 512MB
- Prevent resource exhaustion

### 5. Health Check
```yaml
healthcheck:
  test: ["CMD", "node", "-e", "..."]
  interval: 30s
  retries: 3
```
**GI·∫¢I TH√çCH:**
- Health check script
- Run m·ªói 30s
- Fail sau 3 retries
- Docker Compose s·∫Ω restart container n·∫øu unhealthy

---

## üéØ T·ªîNG K·∫æT

### T·∫§T C·∫¢ C√ÅC FILES V√Ä M·ª§C ƒê√çCH:

| File | M·ª•c ƒë√≠ch | Khi n√†o c·∫ßn |
|------|----------|-------------|
| **learn.dockerfile** | Build Docker image | Lu√¥n c·∫ßn |
| **.dockerignore** | Exclude files kh·ªèi build context | Lu√¥n c·∫ßn |
| **seccomp-profile.json** | Filter system calls | Production (Linux) |
| **apparmor-profile** | Mandatory access control | Production (Linux) |
| **kubernetes-security.yaml** | Deploy l√™n Kubernetes | N·∫øu d√πng K8s |
| **docker-compose-security.yaml** | Run local/small production | N·∫øu d√πng Docker Compose |

### QUY TR√åNH HO√ÄN CH·ªàNH:

1. **Code** ‚Üí Vi·∫øt code
2. **Build** ‚Üí `docker build -f learn.dockerfile -t myapp:1.0.0 .`
3. **Scan** ‚Üí Trivy scan t·ª± ƒë·ªông trong build
4. **Test local** ‚Üí `docker-compose -f docker-compose-security.yaml up`
5. **Deploy** ‚Üí `kubectl apply -f kubernetes-security.yaml`

### SECURITY LAYERS (T·ª™ NGO·∫†I ‚Üí TRONG):

```
1. Network Policy (Kubernetes)         ‚Üí Firewall
2. Seccomp Profile                     ‚Üí System call filtering
3. AppArmor Profile                    ‚Üí Filesystem access control
4. Read-only Filesystem                ‚Üí Prevent writes
5. Non-root User                       ‚Üí Least privilege
6. Capabilities Drop                   ‚Üí Minimal kernel permissions
7. Resource Limits                     ‚Üí Prevent DoS
8. Health Checks                       ‚Üí Auto-restart if fail
```

---

## üöÄ GI·∫¢I TH√çCH JENKINSFILE - T·ª™ ZERO ƒê·∫æN ADVANCE

---

### üìå Jenkins L√† G√¨?

**Jenkins** l√† **open-source automation server** d√πng ƒë·ªÉ:
- CI/CD (Continuous Integration/Continuous Deployment)
- Automate build, test, deploy
- Pipeline as Code

**V√≠ d·ª• d·ªÖ hi·ªÉu:**
```
Jenkins = Robot l·∫≠p tr√¨nh vi√™n
- T·ª± ƒë·ªông l·∫•y code m·ªõi
- Build ·ª©ng d·ª•ng
- Ch·∫°y tests
- Deploy l√™n server
- Th√¥ng b√°o k·∫øt qu·∫£
```

---

### üìñ C√ÅC FILE H·ªåC JENKINSFILE:

| File | M·ª•c ƒë√≠ch | Khi n√†o d√πng |
|------|----------|--------------|
| **learn.jenkinsfile** | File ƒë·∫ßy ƒë·ªß v·ªõi comments chi ti·∫øt | H·ªçc c√°ch vi·∫øt Jenkinsfile |
| **practice.jenkinsfile** | File c√≥ ch·ªó tr·ªëng ƒë·ªÉ ƒëi·ªÅn | Th·ª±c h√†nh, ki·ªÉm tra ki·∫øn th·ª©c |
| **Jenkinsfile** | File th·ª±c t·∫ø cho project | D√πng trong production |

---

### üî§ C·∫§U TR√öC C∆† B·∫¢N C·ª¶A JENKINSFILE

```groovy
pipeline {
    agent any                          // B·∫Øt bu·ªôc: n∆°i ch·∫°y pipeline
    options { ... }                    // Tu·ª≥ ch·ªçn: timeout, timestamps
    parameters { ... }                 // Input parameters
    environment { ... }                // Bi·∫øn m√¥i tr∆∞·ªùng
    tools { ... }                      // Tools (Maven, Node.js)
    triggers { ... }                   // T·ª± ƒë·ªông ch·∫°y

    stages {                           // B·∫Øt bu·ªôc: c√°c stages
        stage('Stage 1') {
            steps {
                // Commands
            }
        }
    }

    post {                             // Sau khi build xong
        success { ... }
        failure { ... }
        always { ... }
    }
}
```

---

### üìù SECTION 1: PIPELINE DECLARATION

```groovy
pipeline {
```
**GI·∫¢I TH√çCH:**
- **`pipeline`**: Keyword khai b√°o Declarative Pipeline
- Declarative syntax = d·ªÖ ƒë·ªçc, d·ªÖ maintain
- Ph·∫£i c√≥ `{` m·ªü block

**Syntax alternatives:**
```groovy
// Declarative (Recommended)
pipeline {
    agent any
    stages { ... }
}

// Scripted (Older, flexible but harder)
node {
    stage('Build') {
        sh 'make'
    }
}
```

---

### üìù SECTION 2: AGENT - N∆†I CH·∫†Y PIPELINE

```groovy
agent any
```
**GI·∫¢I TH√çCH:**
- **`agent`**: Ch·ªâ ƒë·ªãnh n∆°i Jenkins ch·∫°y pipeline
- **`any`**: Ch·∫°y tr√™n b·∫•t k·ª≥ available agent n√†o

**C√°c options:**

```groovy
// 1. any - B·∫•t k·ª≥ agent n√†o
agent any

// 2. none - Kh√¥ng c√≥ default agent, m·ªói stage t·ª± define
agent none

// 3. label - Ch·∫°y tr√™n agent c·ª• th·ªÉ
agent { label 'linux-agent' }

// 4. node - T∆∞∆°ng t·ª± label
agent { node { label 'linux' } }

// 5. Docker - Ch·∫°y trong container
agent {
    docker {
        image 'node:20-alpine'
        reuseNode true
    }
}
```

**V√≠ d·ª• th·ª±c t·∫ø:**
```groovy
// Ch·∫°y tr√™n agent c√≥ label "kubernetes"
agent { label 'kubernetes' }

// Ch·∫°y trong Docker container
agent {
    docker {
        image 'python:3.11'
        args '-v $HOME:/home'
    }
}
```

---

### üìù SECTION 3: OPTIONS - C·∫§U H√åNH PIPELINE

```groovy
options {
    timeout(time: 1, unit: 'HOURS')
    timestamps()
    disableConcurrentBuilds()
}
```

**GI·∫¢I TH√çCH T·ª™NG OPTION:**

#### 3.1 TIMEOUT
```groovy
timeout(time: 1, unit: 'HOURS')
```
**GI·∫¢I TH√çCH:**
- **`timeout`**: Gi·ªõi h·∫°n th·ªùi gian ch·∫°y pipeline
- **`time: 1`**: S·ªë l∆∞·ª£ng
- **`unit: 'HOURS'`**: ƒê∆°n v·ªã th·ªùi gian
- **Units:** `'SECONDS'`, `'MINUTES'`, `'HOURS'`, `'DAYS'`

**T·∫°i sao c·∫ßn?**
- NgƒÉn pipeline ch·∫°y m√£i (hung builds)
- Auto abort n·∫øu timeout
- Gi·∫£i ph√≥ng resources

#### 3.2 TIMESTAMPS
```groovy
timestamps()
```
**GI·∫¢I TH√çCH:**
- Hi·ªÉn th·ªã timestamps trong console output
- **V√≠ d·ª•:**
```
[2025-01-15T10:30:45.123Z] + npm install
[2025-01-15T10:31:20.456Z] Finished: SUCCESS
```

#### 3.3 DISABLE CONCURRENT BUILDS
```groovy
disableConcurrentBuilds()
```
**GI·∫¢I TH√çCH:**
- Kh√¥ng cho ph√©p nhi·ªÅu b·∫£n c·ªßa pipeline ch·∫°y c√πng l√∫c
- **V√≠ d·ª•:**
  ```
  Pipeline A ƒëang ch·∫°y ‚Üí Trigger l·∫°i
  ‚Üí Build m·ªõi s·∫Ω queue ch·ªù build c≈© xong
  ```

**T·∫°i sao c·∫ßn?**
- Tr√°nh xung ƒë·ªôt resources
- Deploy kh√¥ng b·ªã overwrite

**C√°c options kh√°c:**
```groovy
options {
    // Gi·ªØ l·∫°i 10 builds cu·ªëi
    buildDiscarder(logRotator(numToKeepStr: '10'))

    // Skip stages sau khi unstable
    skipStagesAfterUnstable()

    // Th√™m timestamps cho t·∫•t c·∫£ build logs
    timestamps()

    // Retry khi fail
    retry(3)
}
```

---

### üìù SECTION 4: PARAMETERS - INPUT PARAMETERS

```groovy
parameters {
    choice(
        name: 'ENVIRONMENT',
        choices: ['dev', 'staging', 'production'],
        description: 'Ch·ªçn m√¥i tr∆∞·ªùng deploy'
    )
}
```

**GI·∫¢I TH√çCH:**
- **`parameters`**: Input cho ng∆∞·ªùi d√πng khi trigger build
- Cho ph√©p customize m·ªói build

**C√°c lo·∫°i parameters:**

#### 4.1 CHOICE PARAMETER
```groovy
choice(
    name: 'ENVIRONMENT',
    choices: ['dev', 'staging', 'production'],
    description: 'Ch·ªçn m√¥i tr∆∞·ªùng'
)
```
**GI·∫¢I TH√çCH:**
- **`name`**: T√™n parameter (access via `params.ENVIRONMENT`)
- **`choices`**: List c√°c options (dropdown trong UI)
- **`description`**: Ghi ch√∫

**S·ª≠ d·ª•ng:**
```groovy
steps {
    sh "echo Deploying to ${params.ENVIRONMENT}"
}
```

#### 4.2 BOOLEAN PARAMETER
```groovy
booleanParam(
    name: 'RUN_TESTS',
    defaultValue: true,
    description: 'C√≥ ch·∫°y tests kh√¥ng?'
)
```
**GI·∫¢I TH√çCH:**
- Checkbox (true/false)
- **Usage:**
```groovy
when {
    expression { params.RUN_TESTS == true }
}
steps {
    sh 'npm test'
}
```

#### 4.3 STRING PARAMETER
```groovy
string(
    name: 'VERSION',
    defaultValue: '1.0.0',
    description: 'Version c·ªßa release'
)
```
**GI·∫¢I TH√çCH:**
- Text input (single line)
- **Usage:**
```groovy
sh "docker tag myapp:${params.VERSION}"
```

#### 4.4 TEXT PARAMETER
```groovy
text(
    name: 'COMMIT_MESSAGE',
    defaultValue: '',
    description: 'Commit message (multiline)'
)
```
**GI·∫¢I TH√çCH:**
- Multiline text area
- D√πng cho changelog, release notes

#### 4.5 PASSWORD PARAMETER
```groovy
password(
    name: 'API_KEY',
    description: 'API Key cho deployment'
)
```
**GI·∫¢I TH√çCH:**
- Masked input (·∫©n text)
- Secure cho secrets

**‚ö†Ô∏è WARNING:**
- Password parameters v·∫´n visible trong log n·∫øu echo
- Better: Use Jenkins Credentials

---

### üìù SECTION 5: ENVIRONMENT VARIABLES

```groovy
environment {
    APP_NAME = 'my-application'
    DEPLOY_ENV = "${params.ENVIRONMENT}"
    BUILD_DIR = "${WORKSPACE}/build"
}
```

**GI·∫¢I TH√çCH:**
- **`environment`**: Bi·∫øn m√¥i tr∆∞·ªùng global
- Available trong t·∫•t c·∫£ stages

**C√°ch s·ª≠ d·ª•ng:**

#### 5.1 STATIC VALUE
```groovy
environment {
    NODE_ENV = 'production'
}
```
**GI·∫¢I TH√çCH:**
- String value
- **Access:** `${env.NODE_ENV}` or `"$NODE_ENV"`

#### 5.2 FROM PARAMETERS
```groovy
environment {
    DEPLOY_ENV = "${params.ENVIRONMENT}"
}
```
**GI·∫¢I TH√çCH:**
- L·∫•y gi√° tr·ªã t·ª´ parameter
- Double quotes required for interpolation

#### 5.3 BUILT-IN VARIABLES
```groovy
environment {
    WORKSPACE_PATH = "${WORKSPACE}"      // Jenkins workspace directory
    BUILD_NUMBER_STR = "${BUILD_NUMBER}" // Build number (e.g., 123)
    JOB_NAME_STR = "${JOB_NAME}"         // Job name
}
```
**C√°c built-in variables:**
```
WORKSPACE       ‚Üí /var/jenkins_home/workspace/my-job
BUILD_NUMBER    ‚Üí 123
BUILD_ID        ‚Üí 2025-01-15_10-30-45
BUILD_URL       ‚Üí http://jenkins:8080/job/my-job/123/
JOB_NAME        ‚Üí my-job
NODE_NAME       ‚Üí agent-1
```

#### 5.4 ENVIRONMENT ·ªû STAGE LEVEL
```groovy
stage('Build') {
    environment {
        NODE_ENV = 'development'  // Override global
    }
    steps {
        sh 'echo $NODE_ENV'  // ‚Üí "development"
    }
}
```

**Best Practice:**
```groovy
// Global environment
environment {
    APP_NAME = 'myapp'
    VERSION = "${params.VERSION}"
}

// Stage-specific (override if needed)
stage('Test') {
    environment {
        NODE_ENV = 'test'
    }
    steps { ... }
}
```

---

### üìù SECTION 6: TOOLS

```groovy
tools {
    maven 'Maven-3.9'
    nodejs 'Node-20'
}
```

**GI·∫¢I TH√çCH:**
- **`tools`**: Auto-install/configure tools
- Tool name ph·∫£i match v·ªõi Jenkins Global Tool Configuration

**C√°c tools h·ªó tr·ª£:**
```groovy
tools {
    // Maven
    maven 'Maven-3.9'

    // Node.js (c·∫ßn Node.js plugin)
    nodejs 'Node-20'

    // JDK
    jdk 'JDK-17'

    // Gradle
    gradle 'Gradle-8'
}
```

**C·∫•u h√¨nh trong Jenkins:**
1. Manage Jenkins ‚Üí Global Tool Configuration
2. Add Maven/Node.js/JDK installations
3. Set name (e.g., "Node-20")
4. Reference trong Jenkinsfile

**‚ö†Ô∏è L∆∞u √Ω:**
- Ch·ªâ install tool, kh√¥ng set PATH
- Agent ph·∫£i c√≥ tool installer

---

### üìù SECTION 7: STAGES

```groovy
stages {
    stage('Checkout') {
        steps {
            checkout scm
        }
    }
}
```

**GI·∫¢I TH√çCH:**
- **`stages`**: Ch·ª©a c√°c execution stages
- M·ªói `stage` = 1 b∆∞·ªõc trong pipeline
- **`steps`**: Commands ƒë·ªÉ execute

**Structure:**
```groovy
stages {              // B·∫Øt bu·ªôc
    stage('Name') {   // T√™n stage (hi·ªÉn th·ªã trong UI)
        steps {       // B·∫Øt bu·ªôc
            // Commands
        }
        post {        // Optional
            // Actions after stage completes
        }
    }
}
```

---

### üìù SECTION 8: STAGE EXAMPLES

#### 8.1 CHECKOUT STAGE
```groovy
stage('Checkout') {
    steps {
        echo '=== STAGE: CHECKOUT ==='
        checkout scm
    }
}
```
**GI·∫¢I TH√çCH:**
- **`checkout scm`**: L·∫•y code t·ª´ SCM (Git, SVN, etc.)
- `scm` = bi·∫øn Jenkins t·ª± ƒë·ªông inject
- **L√†m g√¨:**
  - Git clone
  - Switch branch
  - Pull latest commits

**Custom checkout:**
```groovy
git url: 'https://github.com/user/repo.git', branch: 'main'
```

#### 8.2 PREPARE STAGE
```groovy
stage('Prepare Environment') {
    steps {
        script {
            // Script block = vi·∫øt Groovy code
            echo "Job: ${env.JOB_NAME}"
            echo "Build: ${env.BUILD_NUMBER}"

            // L·∫•y Git info
            env.GIT_COMMIT = sh(
                script: 'git rev-parse HEAD',
                returnStdout: true
            ).trim()
        }

        // T·∫°o directories
        sh '''
            mkdir -p reports
            mkdir -p artifacts
        '''
    }
}
```
**GI·∫¢I TH√çCH:**
- **`script { ... }`**: Block ƒë·ªÉ vi·∫øt Groovy code
- **`sh '...'`**: Ch·∫°y shell commands
- **`returnStdout: true`**: Capture output
- **`.trim()`**: Remove whitespace

**V√≠ d·ª• output:**
```
Job: my-project
Build: 123
Git Commit: a1b2c3d4e5f6...
```

#### 8.3 INSTALL DEPENDENCIES STAGE
```groovy
stage('Install Dependencies') {
    steps {
        sh '''
            if [ -f package-lock.json ]; then
                npm ci --no-fund --no-audit
            else
                npm install --no-fund --no-audit
            fi
        '''
    }
}
```
**GI·∫¢I TH√çCH:**
- **`npm ci`**: Clean install (faster, deterministic)
- **`--no-fund`**: Kh√¥ng hi·ªÉn th·ªã funding message
- **`--no-audit`**: Kh√¥ng run audit (CI environment)

**Python equivalent:**
```groovy
sh 'pip install -r requirements.txt'
```

**Maven equivalent:**
```groovy
sh 'mvn dependency:go-offline'
```

#### 8.4 BUILD STAGE
```groovy
stage('Build') {
    steps {
        sh 'npm run build --if-present'
    }
}
```
**GI·∫¢I TH√çCH:**
- **`--if-present`**: Kh√¥ng error n·∫øu script kh√¥ng t·ªìn t·∫°i
- Jenkinsfile s·∫Ω continue ngay c·∫£ khi kh√¥ng c√≥ build script

**C√°c build commands:**
```groovy
// Node.js
sh 'npm run build'

// Maven
sh 'mvn package -DskipTests'

// Gradle
sh './gradlew build -x test'

// Docker
sh 'docker build -t myapp:latest .'
```

#### 8.5 TEST STAGE WITH POST
```groovy
stage('Test') {
    steps {
        sh 'npm test --if-present'
    }

    post {
        always {
            // Lu√¥n ch·∫°y (d√π pass hay fail)
            junit 'test-results/*.xml'

            // Publish HTML reports
            publishHTML([
                reportDir: 'coverage',
                reportFiles: 'index.html',
                reportName: 'Coverage Report'
            ])
        }
    }
}
```
**GI·∫¢I TH√çCH:**
- **`post { always { ... } }`**: Lu√¥n execute
- **`junit`**: Publish test results (Jenkins parse)
- **`publishHTML`**: Display HTML reports trong Jenkins UI

**Test report formats:**
```
JUnit XML: test-results/*.xml
Mocha: mocha test --reporter json > test-results.json
pytest: pytest --junitxml=test-results.xml
```

---

### üìù SECTION 9: ADVANCED STAGES - SECURITY SCANNING

#### 9.1 SONARQUBE SCAN
```groovy
stage('SonarQube Scan') {
    when {
        expression { params.RUN_TESTS == true }
    }

    steps {
        withSonarQubeEnv('SonarQube-Server') {
            sh '''
                sonar-scanner \
                    -Dsonar.projectKey=my-project \
                    -Dsonar.sources=src \
                    -Dsonar.host.url=$SONAR_HOST_URL \
                    -Dsonar.login=$SONAR_AUTH_TOKEN
            '''
        }
    }
}
```
**GI·∫¢I TH√çCH:**
- **`when { expression { ... } }`**: Conditional execution
- **`withSonarQubeEnv`**: Inject SonarQube config
- Auto-configure t·ª´ Jenkins global settings

**Setup trong Jenkins:**
1. Manage Jenkins ‚Üí Configure System
2. SonarQube servers ‚Üí Add server
3. Name: "SonarQube-Server"
4. Server URL, authentication token

#### 9.2 QUALITY GATE
```groovy
stage('SonarQube Quality Gate') {
    steps {
        script {
            timeout(time: 10, unit: 'MINUTES') {
                waitForQualityGate abortPipeline: true
            }
        }
    }
}
```
**GI·∫¢I TH√çCH:**
- **`waitForQualityGate`**: Ch·ªù SonarQube analysis ho√†n th√†nh
- **`abortPipeline: true`**: Fail pipeline n·∫øu quality gate kh√¥ng pass
- **`timeout`**: Kh√¥ng ch·ªù qu√° 10 ph√∫t

**Quality Gate Rules:**
- Code coverage > 80%
- No critical vulnerabilities
- Code smell rating = A

#### 9.3 OWASP DEPENDENCY CHECK
```groovy
stage('OWASP Dependency Check') {
    steps {
        sh '''
            dependency-check.sh \
                --format "HTML" \
                --format "XML" \
                --project "MyApp" \
                --out reports/dependency-check \
                --scan .
        '''

        publishHTML([
            target: [
                reportDir: 'reports/dependency-check',
                reportFiles: 'dependency-check-report.html',
                reportName: 'OWASP Dependency Check'
            ]
        ])
    }
}
```
**GI·∫¢I TH√çCH:**
- **`dependency-check.sh`**: OWASP tool
- Scan vulnerabilities trong dependencies
- Ph·∫£i c√†i Dependency-Check plugin tr√™n Jenkins agent

**Output:**
- HTML report (human-readable)
- XML report (machine-readable)

#### 9.4 TRIVY SCAN
```groovy
stage('Trivy Scan') {
    steps {
        sh '''
            trivy fs \
                --format table \
                --output reports/trivy-fs.txt \
                --severity HIGH,CRITICAL \
                .
        '''

        archiveArtifacts artifacts: 'reports/trivy-fs.txt', allowEmptyArchive: true
    }
}
```
**GI·∫¢I TH√çCH:**
- **`trivy fs`**: Scan filesystem
- **`--severity HIGH,CRITICAL`**: Ch·ªâ report high/critical
- **`archiveArtifacts`**: L∆∞u l·∫°i trong Jenkins

**Trivy scan types:**
```groovy
// Filesystem scan
trivy fs .

// Docker image scan
trivy image myapp:latest

// Repository scan
trivy repo https://github.com/user/repo
```

---

### üìù SECTION 10: CONDITIONAL EXECUTION (WHEN)

```groovy
stage('Example') {
    when {
        expression { params.RUN_TESTS == true }
    }
    steps {
        sh 'npm test'
    }
}
```

**GI·∫¢I TH√çCH:**
- **`when`**: Conditional execution cho stage
- Stage ch·ªâ ch·∫°y n·∫øu condition = true

**C√°c types of conditions:**

#### 10.1 EXPRESSION
```groovy
when {
    expression { params.ENVIRONMENT == 'production' }
}
```
**GI·∫¢I TH√çCH:**
- Groovy boolean expression
- Return true/false

**Examples:**
```groovy
// Parameter check
expression { params.DEPLOY == true }

// File exists check
expression { fileExists('Dockerfile') }

// Multiple conditions
expression {
    return params.ENVIRONMENT == 'prod' &&
           params.DEPLOY == true
}
```

#### 10.2 BRANCH
```groovy
when {
    branch 'main'
}
```
**GI·∫¢I TH√çCH:**
- Ch·ªâ ch·∫°y khi build t·ª´ branch c·ª• th·ªÉ
- **Example:**
```groovy
when {
    anyOf {
        branch 'main'
        branch 'develop'
    }
}
```

#### 10.3 TAG
```groovy
when {
    tag 'v*'
}
```
**GI·∫¢I TH√çCH:**
- Ch·ªâ ch·∫°y khi Git tag match pattern
- **Pattern examples:**
  - `v*` ‚Üí v1.0.0, v2.0.0
  - `release-*` ‚Üí release-1.0, release-2.0

#### 10.4 CHANGE REQUEST
```groovy
when {
    changeRequest()
}
```
**GI·∫¢I TH√çCH:**
- Ch·ªâ ch·∫°y khi build = PR/MR
- **GitHub PR, GitLab MR, Bitbucket PR**

#### 10.5 ENVIRONMENT
```groovy
when {
    environment name: 'DEPLOY_TO', value: 'production'
}
```
**GI·∫¢I TH√çCH:**
- Check environment variable

#### 10.6 COMBINING CONDITIONS
```groovy
// AND (allOf)
when {
    allOf {
        branch 'main'
        expression { params.DEPLOY == true }
    }
}

// OR (anyOf)
when {
    anyOf {
        branch 'main'
        branch 'develop'
    }
}

// NOT
when {
    not {
        branch 'feature/*'
    }
}
```

---

### üìù SECTION 11: POST BUILD ACTIONS

```groovy
post {
    success { ... }
    failure { ... }
    always { ... }
}
```

**GI·∫¢I TH√çCH:**
- **`post`**: Actions sau khi build xong
- Run regardless c·ªßa build result

**C√°c conditions:**

#### 11.1 SUCCESS
```groovy
success {
    echo '=== BUILD SUCCESS ==='
    script {
        // Tag release
        sh "git tag v${params.VERSION}"
        sh "git push origin v${params.VERSION}"
    }
}
```
**GI·∫¢I TH√çCH:**
- Ch·∫°y khi build = SUCCESS
- T·∫•t c·∫£ stages pass

#### 11.2 FAILURE
```groovy
failure {
    echo '=== BUILD FAILED ==='
    emailext(
        subject: "Build FAILED: ${env.JOB_NAME}",
        body: "Check console: ${env.BUILD_URL}console",
        to: 'devops@example.com'
    )
}
```
**GI·∫¢I TH√çCH:**
- Ch·∫°y khi build = FAILURE
- B·∫•t k·ª≥ stage fail ho·∫∑c error

#### 11.3 ABORTED
```groovy
aborted {
    echo '=== BUILD ABORTED ==='
}
```
**GI·∫¢I TH√çCH:**
- User cancel build

#### 11.4 UNSTABLE
```groovy
unstable {
    echo '=== BUILD UNSTABLE ==='
}
```
**GI·∫¢I TH√çCH:**
- Build success nh∆∞ng tests fail
- Ho·∫∑c quality gate kh√¥ng pass

#### 11.5 ALWAYS
```groovy
always {
    echo '=== CLEANUP ==='
    cleanWs()
}
```
**GI·∫¢I TH√çCH:**
- **LU√îN LU√îN ch·∫°y**
- D√πng cho cleanup
- Archive artifacts

**Full example:**
```groovy
post {
    success {
        echo 'Build passed!'
        sh 'notify.sh success'
    }
    failure {
        echo 'Build failed!'
        sh 'notify.sh failure'
    }
    always {
        // Archive
        archiveArtifacts 'dist/**/*'

        // Clean workspace
        cleanWs()
    }
}
```

---

### üìù SECTION 12: ADVANCED FEATURES

#### 12.1 PARALLEL EXECUTION
```groovy
stage('Parallel Tests') {
    steps {
        script {
            parallel(
                "Unit Tests": {
                    echo 'Running unit tests...'
                    sh 'npm run test:unit'
                },
                "Integration Tests": {
                    echo 'Running integration tests...'
                    sh 'npm run test:integration'
                },
                "E2E Tests": {
                    echo 'Running E2E tests...'
                    sh 'npm run test:e2e'
                }
            )
        }
    }
}
```
**GI·∫¢I TH√çCH:**
- **`parallel`**: Ch·∫°y song song
- Speed up pipeline
- C·∫ßn enough agents

**Benefits:**
```
Sequential: 30 minutes (10 + 10 + 10)
Parallel:   10 minutes (max c·ªßa 3 stages)
```

#### 12.2 MATRIX BUILDS
```groovy
stage('Matrix Build') {
    matrix {
        axes {
            axis {
                name 'NODE_VERSION'
                values '18', '20', '21'
            }
            axis {
                name 'OS'
                values 'linux', 'windows'
            }
        }
        stages {
            stage('Build') {
                steps {
                echo "Building on Node ${NODE_VERSION} - ${OS}"
                sh 'npm run build'
            }
        }
    }
}
```
**GI·∫¢I TH√çCH:**
- Test tr√™n nhi·ªÅu combinations
- Total builds: 3 √ó 2 = 6
- Matrix:
  - Node 18 + Linux
  - Node 18 + Windows
  - Node 20 + Linux
  - Node 20 + Windows
  - Node 21 + Linux
  - Node 21 + Windows

#### 12.3 INPUT APPROVAL
```groovy
stage('Deploy to Production') {
    steps {
        input message: 'Approve deployment?', ok: 'Deploy'

        sh 'kubectl apply -f prod/'
    }
}
```
**GI·∫¢I TH√çCH:**
- **`input`**: Manual approval gate
- Pipeline pause v√† ch·ªù user input
- **Options:**
```groovy
input(
    message: 'Deploy to production?',
    ok: 'Deploy',
    submitter: 'admin,ops-team',  // Ch·ªâ user n√†y ƒë∆∞·ª£c approve
    submitterParameter: 'APPROVER'
)
```

#### 12.4 CREDENTIALS MANAGEMENT
```groovy
stage('Deploy') {
    steps {
        withCredentials([
            string(
                credentialsId: 'api-token',
                variable: 'API_TOKEN'
            ),
            usernamePassword(
                credentialsId: 'docker-registry',
                usernameVariable: 'DOCKER_USER',
                passwordVariable: 'DOCKER_PASS'
            )
        ]) {
            sh '''
                echo $API_TOKEN
                docker login -u $DOCKER_USER -p $DOCKER_PASS
            '''
        }
    }
}
```
**GI·∫¢I TH√çCH:**
- **`withCredentials`**: Inject credentials
- Credentials stored trong Jenkins (encrypted)
- Auto mask trong logs

**‚ö†Ô∏è SECURITY:**
- KH√îNG BAO GI·ªú echo secrets
- Use credentials management
- Not hardcode trong Jenkinsfile

#### 12.5 NOTIFICATIONS
```groovy
post {
    always {
        script {
            def status = currentBuild.result ?: 'SUCCESS'

            // Slack
            slackSend(
                color: status == 'SUCCESS' ? 'good' : 'danger',
                message: "Build ${status}: ${env.JOB_NAME} - ${env.BUILD_NUMBER}"
            )

            // Email
            emailext(
                subject: "Build ${status}: ${env.JOB_NAME}",
                body: """
                    Status: ${status}
                    Console: ${env.BUILD_URL}console
                """,
                to: 'team@example.com'
            )

            // Microsoft Teams
            office365ConnectorSend(
                webhookUrl: 'TEAMS_WEBHOOK_URL',
                status: status
            )
        }
    }
}
```

---

### üìù SECTION 13: BEST PRACTICES

#### ‚úÖ 1. S·ª¨ D·ª§NG DECLARATIVE SYNTAX
```groovy
// ‚úÖ GOOD
pipeline {
    agent any
    stages { ... }
}

// ‚ùå AVOID (n·∫øu c√≥ th·ªÉ)
node {
    stage('Build') {
        sh 'make'
    }
}
```

#### ‚úÖ 2. LU√îN LU√îN C√ì TIMEOUT
```groovy
options {
    timeout(time: 1, unit: 'HOURS')
}
```

#### ‚úÖ 3. S·ª¨ D·ª§NG PARAMETERS CHO FLEXIBILITY
```groovy
parameters {
    booleanParam(name: 'RUN_TESTS', defaultValue: true)
}
```

#### ‚úÖ 4. ARCHIVE ARTIFACTS
```groovy
post {
    always {
        archiveArtifacts artifacts: 'dist/**/*'
    }
}
```

#### ‚úÖ 5. CLEAN WORKSPACE
```groovy
post {
    always {
        cleanWs()
    }
}
```

#### ‚úÖ 6. SECURITY SCANNING
```groovy
stage('Security Scan') {
    steps {
        sh 'trivy fs .'
    }
}
```

#### ‚úÖ 7. MANUAL APPROVAL CHO PRODUCTION
```groovy
stage('Deploy to Prod') {
    steps {
        input message: 'Approve?'
        sh 'kubectl apply -f prod/'
    }
}
```

#### ‚úÖ 8. PARALLEL EXECUTION
```groovy
parallel(
    "Test 1": { sh 'npm run test:1' },
    "Test 2": { sh 'npm run test:2' }
)
```

#### ‚úÖ 9. USE CREDENTIALS MANAGEMENT
```groovy
withCredentials([string(credentialsId: 'token', variable: 'TOKEN')]) {
    sh 'echo $TOKEN'  // Masked trong logs
}
```

#### ‚úÖ 10. ERROR HANDLING
```groovy
steps {
    script {
        try {
            sh 'npm run build'
        } catch (e) {
            echo "Build failed: ${e}"
            currentBuild.result = 'FAILURE'
            throw e
        }
    }
}
```

---

### üéØ T·ªîNG K·∫æT - JENKINSFILE WORKFLOW

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    JENKINS PIPELINE                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Trigger build (manual, webhook, schedule)               ‚îÇ
‚îÇ  2. Checkout code                                            ‚îÇ
‚îÇ  3. Prepare environment                                      ‚îÇ
‚îÇ  4. Install dependencies                                     ‚îÇ
‚îÇ  5. Build application                                        ‚îÇ
‚îÇ  6. Run tests                                               ‚îÇ
‚îÇ  7. Security scanning (SonarQube, OWASP, Trivy)              ‚îÇ
‚îÇ  8. Docker build (optional)                                  ‚îÇ
‚îÇ  9. Deploy (with approval for production)                   ‚îÇ
‚îÇ  10. Notify (email, Slack, etc.)                            ‚îÇ
‚îÇ  11. Post-build actions (cleanup, archive)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### üìù SECTION 20: ADVANCED FEATURES - EXPERT LEVEL

#### 20.1 KUBERNETES AGENT

```groovy
agent {
    kubernetes {
        label 'my-pod'
        yaml '''
            apiVersion: v1
            kind: Pod
            metadata:
              labels:
                app: jenkins-agent
            spec:
              containers:
              - name: jnlp
                image: jenkins/inbound-agent:latest
              - name: node
                image: node:20-alpine
                command:
                - cat
                tty: true
              - name: docker
                image: docker:latest
                command:
                - cat
                tty: true
                volumeMounts:
                - mountPath: /var/run/docker.sock
                  name: docker-sock
              volumes:
              - name: docker-sock
                hostPath:
                  path: /var/run/docker.sock
        '''
    }
}
```

**GI·∫¢I TH√çCH:**
- **`kubernetes` agent**: Ch·∫°y pipeline trong Kubernetes pod
- **`yaml`**: Pod specification
- **Multiple containers**: Node.js, Docker, tools trong c√πng pod
- **Volume mounts**: Mount Docker socket ƒë·ªÉ ch·∫°y Docker-in-Docker

#### 20.2 MATRIX BUILDS - MULTI-CONFIGURATION TESTING

```groovy
stage('Matrix Build') {
    matrix {
        axes {
            axis {
                name 'NODE_VERSION'
                values '18', '20', '21'
            }
            axis {
                name 'OS'
                values 'linux', 'windows'
            }
        }
        stages {
            stage('Build') {
                steps {
                    echo "Building on Node ${NODE_VERSION} - ${OS}"
                    sh "npm run build"
                }
            }
            stage('Test') {
                steps {
                    echo "Testing on Node ${NODE_VERSION} - ${OS}"
                    sh "npm test"
                }
            }
        }
        excludes {
            exclude {
                axis {
                    name 'NODE_VERSION'
                    values '18'
                }
                axis {
                    name 'OS'
                    values 'windows'
                }
            }
        }
    }
}
```

**GI·∫¢I TH√çCH:**
- **`matrix`**: Ch·∫°y song song nhi·ªÅu configurations
- **`axes`**: C√°c dimensions ƒë·ªÉ test (Node version, OS, etc.)
- **Total builds**: 3 √ó 2 = 6 builds
- **`excludes`**: Lo·∫°i b·ªè c√°c combinations kh√¥ng c·∫ßn thi·∫øt
- **Parallel execution**: T·∫•t c·∫£ matrix builds ch·∫°y song song

#### 20.3 SHARED LIBRARIES - COMPLETE GUIDE

**Library Structure:**
```
shared-library/
‚îú‚îÄ‚îÄ vars/
‚îÇ   ‚îú‚îÄ‚îÄ standardBuild.groovy
‚îÇ   ‚îú‚îÄ‚îÄ deploy.groovy
‚îÇ   ‚îî‚îÄ‚îÄ notify.groovy
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ com/example/
‚îÇ       ‚îú‚îÄ‚îÄ Utils.groovy
‚îÇ       ‚îî‚îÄ‚îÄ Docker.groovy
‚îî‚îÄ‚îÄ resources/
    ‚îî‚îÄ‚îÄ org/jenkinsci/plugins/pipeline/
        ‚îî‚îÄ‚îÄ status_messages.properties
```

**Using Shared Library:**
```groovy
@Library('shared-lib@main') _

pipeline {
    agent any
    stages {
        stage('Standard Build') {
            steps {
                // G·ªçi function t·ª´ vars/
                standardBuild()
            }
        }

        stage('Deploy') {
            steps {
                script {
                    // G·ªçi function v·ªõi parameters
                    deploy(
                        environment: 'production',
                        strategy: 'blue-green'
                    )
                }
            }
        }
    }
}
```

**Custom Function Example (vars/standardBuild.groovy):**
```groovy
def call(Map config = [:]) {
    pipeline {
        agent any

        options {
            timeout(time: config.timeout ?: 1, unit: 'HOURS')
        }

        stages {
            stage('Build') {
                steps {
                    sh 'npm run build'
                }
            }

            stage('Test') {
                when {
                    expression { config.skipTests != true }
                }
                steps {
                    sh 'npm test'
                }
            }
        }
    }
}
```

#### 20.4 BLUE-GREEN DEPLOYMENT

```groovy
stage('Blue-Green Deployment') {
    steps {
        script {
            // Get current color
            def currentColor = sh(
                script: 'kubectl get service ${APP_NAME} -o jsonpath="{.spec.selector.color}"',
                returnStdout: true
            ).trim()

            def newColor = currentColor == 'blue' ? 'green' : 'blue'

            echo "Current: ${currentColor}, New: ${newColor}"

            // Deploy to new color
            sh """
                kubectl apply -f k8s/${newColor}/
                kubectl wait --for=condition=ready pod -l color=${newColor} --timeout=300s
            """

            // Switch traffic
            sh """
                kubectl patch service ${APP_NAME} -p '{"spec":{"selector":{"color":"${newColor}"}}}'
            """

            // Monitor for rollback
            timeout(time: 5, unit: 'MINUTES') {
                sh '''
                    # Health checks
                    for i in {1..30}; do
                        if curl -f ${HEALTH_URL}; then
                            echo "Health check passed"
                            break
                        fi
                        sleep 10
                    done
                '''
            }

            // Cleanup old deployment after success
            sh "kubectl delete -f k8s/${currentColor}/"
        }
    }
}
```

**GI·∫¢I TH√çCH:**
- **Blue-Green**: 2 environments gi·ªëng h·ªát nhau
- **Zero downtime**: Switch traffic instant
- **Easy rollback**: Switch back n·∫øu c√≥ v·∫•n ƒë·ªÅ
- **Resource intensive**: C·∫ßn 2x resources

#### 20.5 CANARY DEPLOYMENT

```groovy
stage('Canary Deployment') {
    steps {
        script {
            // Start with 10%
            def canaryPercentages = [10, 25, 50, 100]

            canaryPercentages.each { percent ->
                echo "Canary deployment: ${percent}%"

                // Update canary percentage
                sh """
                    kubectl patch deployment ${APP_NAME}-canary \
                        -p '{"spec":{"replicas":${(TOTAL_REPLICATES * percent / 100).intValue()}}}'
                """

                // Update traffic split via Istio
                sh """
                    istioctl replace -f - <<EOF
                    apiVersion: networking.istio.io/v1beta1
                    kind: VirtualService
                    metadata:
                      name: ${APP_NAME}
                    spec:
                      http:
                      - route:
                        - destination:
                            host: ${APP_NAME}
                            subset: stable
                          weight: ${100 - percent}
                        - destination:
                            host: ${APP_NAME}
                            subset: canary
                          weight: ${percent}
                    EOF
                """

                // Monitor metrics
                sleep(time: 5, unit: 'MINUTES')

                // Check error rate
                def errorRate = sh(
                    script: """
                        curl -s ${METRICS_URL}/error-rate
                    """,
                    returnStdout: true
                ).trim() as double

                if (errorRate > 0.01) {  // 1% error rate
                    error("Canary failed! Error rate: ${errorRate}%")
                }
            }

            // Promote canary to stable
            sh """
                kubectl scale deployment ${APP_NAME} --replicas=${TOTAL_REPLICATES}
                kubectl delete deployment ${APP_NAME}-canary
            """
        }
    }
}
```

**GI·∫¢I TH√çCH:**
- **Canary**: Gradual rollout (10% ‚Üí 25% ‚Üí 50% ‚Üí 100%)
- **Traffic splitting**: Via Istio, NGINX, or ALB
- **Monitoring**: Check metrics t·∫°i m·ªói step
- **Auto-rollback**: N·∫øu error rate > threshold

#### 20.6 DISCORD NOTIFICATION

```groovy
stage('Notify') {
    steps {
        script {
            def buildStatus = currentBuild.result ?: 'SUCCESS'
            def color = buildStatus == 'SUCCESS' ? '3066993' : '15158332'  // Decimal colors

            webhook(
                url: 'DISCORD_WEBHOOK_URL',
                contentType: 'APPLICATION_JSON',
                payload: """{
                    "username": "Jenkins",
                    "avatar_url": "https://wiki.jenkins.io/download/attachments/2916393/headshot.png",
                    "embeds": [{
                        "title": "${env.JOB_NAME} - ${buildStatus}",
                        "description": "Build #${env.BUILD_NUMBER}",
                        "color": ${color},
                        "fields": [
                            {"name": "Status", "value": "${buildStatus}", "inline": true},
                            {"name": "Environment", "value": "${params.ENVIRONMENT}", "inline": true},
                            {"name": "Version", "value": "${params.VERSION}", "inline": true},
                            {"name": "Duration", "value": "${currentBuild.durationString}", "inline": true},
                            {"name": "Changes", "value": "${env.GIT_COMMIT_SHORT}", "inline": true}
                        ],
                        "url": "${env.BUILD_URL}"
                    }]
                }"""
            )
        }
    }
}
```

#### 20.7 MICROSOFT TEAMS NOTIFICATION

```groovy
stage('Notify Teams') {
    steps {
        script {
            def buildStatus = currentBuild.result ?: 'SUCCESS'
            def color = buildStatus == 'SUCCESS' ? '00ff00' : 'ff0000'

            office365ConnectorSend(
                webhookUrl: 'TEAMS_WEBHOOK_URL',
                status: buildStatus,
                color: color,
                message: """
                    **Build ${buildStatus}**
                    - Project: ${env.JOB_NAME}
                    - Build: #${env.BUILD_NUMBER}
                    - Environment: ${params.ENVIRONMENT}
                    - Version: ${params.VERSION}
                    - [View Logs](${env.BUILD_URL}console)
                """.stripIndent()
            )
        }
    }
}
```

#### 20.8 HTTP REQUESTS IN PIPELINE

```groovy
stage('API Call') {
    steps {
        script {
            // GET request
            def response = sh(
                script: 'curl -s -X GET https://api.example.com/health',
                returnStdout: true
            )

            // POST request with JSON
            sh '''
                curl -X POST https://api.example.com/deploy \
                    -H "Content-Type: application/json" \
                    -H "Authorization: Bearer ${API_TOKEN}" \
                    -d '{
                        "environment": "${params.ENVIRONMENT}",
                        "version": "${params.VERSION}",
                        "build_url": "${env.BUILD_URL}"
                    }'
            '''

            // Using httpRequest (HTTP Request Plugin)
            httpRequest(
                url: 'https://api.example.com/notify',
                httpMode: 'POST',
                contentType: 'APPLICATION_JSON',
                requestBody: """
                    {"status": "SUCCESS", "build": "${env.BUILD_NUMBER}"}
                """.stripIndent(),
                quiet: true
            )
        }
    }
}
```

#### 20.9 FILE OPERATIONS

```groovy
stage('File Operations') {
    steps {
        script {
            // Read file
            def content = readFile 'config.json'

            // Write file
            writeFile file: 'output.json', text: '{"result": "success"}'

            // Find files
            def files = findFiles(glob: '**/*.jar')

            // Archive files
            archiveArtifacts artifacts: 'target/*.jar'

            // Stash files (save for later)
            stash includes: 'target/*.jar', name: 'build-artifacts'

            // Unstash files
            unstash 'build-artifacts'

            // Delete files
            sh 'rm -rf target/*.jar'

            // Zip files
            sh 'zip -r artifacts.zip dist/'

            // Unzip files
            sh 'unzip artifacts.zip -d output/'
        }
    }
}
```

#### 20.10 ERROR HANDLING STRATEGIES

```groovy
stage('Error Handling') {
    steps {
        script {
            try {
                // Stage code
                sh 'npm run build'

            } catch (Exception e) {
                // Handle specific errors
                if (e.message.contains('Out of memory')) {
                    echo 'Memory error detected, retrying with more memory...'
                    sh 'NODE_OPTIONS="--max-old-space-size=4096" npm run build'
                } else {
                    // Rethrow for other errors
                    throw e
                }

            } finally {
                // Always run cleanup
                sh 'rm -rf tmp/'
            }
        }
    }
}
```

#### 20.11 RETRY STRATEGY

```groovy
stage('Retry') {
    steps {
        retry(3) {
            script {
                sh '''
                    # Attempt operation
                    curl -f https://api.example.com/ping || exit 1
                '''
            }
        }
    }

    post {
        failure {
            echo 'Failed after 3 retries!'
        }
    }
}
```

#### 20.12 TIMEOUT PER STAGE

```groovy
stage('Long Running Task') {
    options {
        timeout(time: 30, unit: 'MINUTES')
    }

    steps {
        sh 'npm run test:integration'
    }

    post {
        failure {
            script {
                if (currentBuild.result == 'ABORTED') {
                    echo 'Stage timed out!'
                }
            }
        }
    }
}
```

---

### üìù SECTION 21: JENKINS PLUGIN ECOSYSTEM

**Must-have Plugins:**

1. **Pipeline** - Declarative pipeline support
2. **Git** - Git integration
3. **GitHub / GitLab / Bitbucket** - SCM integration
4. **Blue Ocean** - Modern UI
5. **Docker Pipeline** - Docker support
6. **Kubernetes** - Kubernetes agents
7. **Config File Provider** - Configuration files
8. **Credentials Binding** - Secure credentials
9. **Workspace Cleanup** - Clean workspace
10. **Timestamper** - Timestamps in logs

**Testing Plugins:**
- **JUnit** - Test results
- **Cobertura** - Code coverage
- **HTML Publisher** - HTML reports

**Security Plugins:**
- **SonarQube Scanner** - Code quality
- **OWASP Dependency-Check** - Vulnerability scanning
- **Trivy** - Container scanning

**Notification Plugins:**
- **Slack** - Slack notifications
- **Email Extension** - Enhanced email
- **Microsoft Teams** - Teams notifications
- **Discord Notifier** - Discord notifications

**Deployment Plugins:**
- **Kubernetes CLI** - kubectl commands
- **AWS Steps** - AWS deployment
- **Azure CLI** - Azure deployment

---

### üéØ JENKINS LEARNING PATH

```
Beginner (Week 1-2):
‚îú‚îÄ‚îÄ Pipeline basics (agent, stages, steps)
‚îú‚îÄ‚îÄ Checkout, build, test stages
‚îú‚îÄ‚îÄ Parameters & environment variables
‚îî‚îÄ‚îÄ Basic post-build actions

Intermediate (Week 3-4):
‚îú‚îÄ‚îÄ Conditional execution (when)
‚îú‚îÄ‚îÄ Parallel execution
‚îú‚îÄ‚îÄ Docker agents
‚îú‚îÄ‚îÄ Credentials management
‚îî‚îÄ‚îÄ Notifications (Slack, email)

Advanced (Week 5-8):
‚îú‚îÄ‚îÄ Security scanning (SonarQube, Trivy, OWASP)
‚îú‚îÄ‚îÄ Matrix builds
‚îú‚îÄ‚îÄ Kubernetes agents
‚îú‚îÄ‚îÄ Shared libraries
‚îú‚îÄ‚îÄ Blue-Green/Canary deployments
‚îî‚îÄ‚îÄ Error handling & retry strategies

Expert (Week 9+):
‚îú‚îÄ‚îÄ Multi-branch pipelines
‚îú‚îÄ‚îÄ Complex deployments
‚îú‚îÄ‚îÄ Custom plugins development
‚îú‚îÄ‚îÄ Pipeline as Code best practices
‚îî‚îÄ‚îÄ Jenkins optimization & scaling
```

---

### üìö T√ÄI LI·ªÜU THAM KH·∫¢O CHO JENKINS:

- **Jenkins Official Docs**: https://www.jenkins.io/doc/
- **Pipeline Syntax**: https://www.jenkins.io/doc/book/pipeline/syntax/
- **Shared Libraries**: https://www.jenkins.io/doc/book/pipeline/shared-libraries/
- **Plugins**: https://plugins.jenkins.io/

---

## üåç GI·∫¢I TH√çCH TERRAFORM - T·ª™ ZERO ƒê·∫æN ADVANCE

---

### üìå Terraform L√† G√¨?

**Terraform** l√† **Infrastructure as Code (IaC)** tool c·ªßa HashiCorp d√πng ƒë·ªÉ:
- Define infrastructure = code
- Provision resources tr√™n multi-cloud (AWS, Azure, GCP, etc.)
- Manage infrastructure lifecycle
- Version control infrastructure changes

**V√≠ d·ª• d·ªÖ hi·ªÉu:**
```
Terraform = Architect t·ª± ƒë·ªông
- B·∫°n vi·∫øt code ‚Üí Terraform ƒë·ªçc v√† build infrastructure
- B·∫°n thay ƒë·ªïi code ‚Üí Terraform c·∫≠p nh·∫≠t infrastructure
- B·∫°n x√≥a code ‚Üí Terraform destroy resources
```

**L·ª£i √≠ch:**
- **Consistent**: Code = infrastructure (kh√¥ng c√≥ manual drift)
- **Reusable**: Modules d√πng l·∫°i cho nhi·ªÅu projects
- **Version controlled**: Git track m·ªçi changes
- **Multi-cloud**: C√πng syntax cho AWS, Azure, GCP, Kubernetes, etc.

---

### üìñ C√ÅC FILE H·ªåC TERRAFORM:

| File | M·ª•c ƒë√≠ch | Khi n√†o d√πng |
|------|----------|--------------|
| **learn.tf** | File ƒë·∫ßy ƒë·ªß v·ªõi comments chi ti·∫øt | H·ªçc c√°ch vi·∫øt Terraform |
| **practice.tf** | File c√≥ ch·ªó tr·ªëng ƒë·ªÉ ƒëi·ªÅn | Th·ª±c h√†nh, ki·ªÉm tra ki·∫øn th·ª©c |
| **main.tf** | File th·ª±c t·∫ø cho project | D√πng trong production |

---

### üî§ C·∫§U TR√öC C∆† B·∫¢N C·ª¶A TERRAFORM

```hcl
terraform {
  required_version = ">= 1.0"
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
  backend "s3" { ... }
}

provider "aws" {
  region = "us-east-1"
}

variable "region" {
  type    = string
  default = "us-east-1"
}

locals {
  name_prefix = "${var.project}-${var.env}"
}

data "aws_vpc" "existing" {
  id = var.vpc_id
}

resource "aws_vpc" "main" {
  cidr_block = "10.0.0.0/16"
}

output "vpc_id" {
  value = aws_vpc.main.id
}

module "vpc" {
  source = "./modules/vpc"
}
```

---

### üìù SECTION 1: TERRAFORM BLOCK

```hcl
terraform {
  required_version = ">= 1.0"

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }

  backend "s3" {
    bucket         = "my-terraform-state"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    encrypt        = true
    dynamodb_table = "terraform-locks"
  }
}
```

**GI·∫¢I TH√çCH:**

#### 1.1 REQUIRED VERSION
```hcl
required_version = ">= 1.0"
```
**GI·∫¢I TH√çCH:**
- Y√™u c·∫ßu Terraform version t·ªëi thi·ªÉu
- **Operators:**
  - `>= 1.0`: Version 1.0 ho·∫∑c cao h∆°n
  - `~> 1.0`: Version 1.x (kh√¥ng jump l√™n 2.0)
  - `= 1.0.0`: Ch√≠nh x√°c version n√†y
- **T·∫°i sao c·∫ßn?**
  - ƒê·∫£m b·∫£o t√≠nh t∆∞∆°ng th√≠ch
  - Tr√°nh breaking changes

#### 1.2 REQUIRED PROVIDERS
```hcl
required_providers {
  aws = {
    source  = "hashicorp/aws"
    version = "~> 5.0"
  }
}
```
**GI·∫¢I TH√çCH:**
- **`source`**: Provider source
  - Format: `<namespace>/<type>`
  - `hashicorp/aws`: Official AWS provider
  - `hashicorp/azurerm`: Azure provider
  - `hashicorp/google`: GCP provider
- **`version`**: Version constraint
  - `~> 5.0`: Version 5.x (5.0, 5.1, 5.2, ...)
  - `>= 4.0`: Version 4.0+
  - L·∫ßn ƒë·∫ßu run: `terraform init` t·∫£i provider

#### 1.3 BACKEND CONFIGURATION
```hcl
backend "s3" {
  bucket         = "my-terraform-state"
  key            = "prod/terraform.tfstate"
  region         = "us-east-1"
  encrypt        = true
  dynamodb_table = "terraform-locks"
}
```
**GI·∫¢I TH√çCH:**
- **Backend**: N∆°i l∆∞u state file
- **State file**: Database c·ªßa Terraform (track t·∫•t c·∫£ resources)
- **S3 backend**:
  - **`bucket`**: S3 bucket name
  - **`key`**: Path to state file
  - **`encrypt`**: Encrypt state at rest
  - **`dynamodb_table`**: Locking state (prevents concurrent modifications)

**C√°c backend types:**
```hcl
# Local backend (default)
backend "local" {
  path = "terraform.tfstate"
}

# S3 backend (recommended for teams)
backend "s3" {
  bucket = "my-state"
  key    = "prod/terraform.tfstate"
  region = "us-east-1"
}

# Azure Blob Storage
backend "azurerm" {
  storage_account_name = "mystorageaccount"
  container_name       = "terraform-state"
  key                  = "prod.terraform.tfstate"
}

# GCS (Google Cloud Storage)
backend "gcs" {
  bucket = "terraform-state"
  prefix = "prod"
}
```

---

### üìù SECTION 2: PROVIDER BLOCKS

```hcl
provider "aws" {
  region = var.aws_region

  default_tags {
    tags = {
      Environment = var.environment
      ManagedBy   = "Terraform"
    }
  }
}
```

**GI·∫¢I TH√çCH:**

#### 2.1 PROVIDER CONFIGURATION
```hcl
provider "aws" {
  region = "us-east-1"
}
```
**GI·∫¢I TH√çCH:**
- **`provider`**: Khai b√°o cloud provider
- **`aws`**: Provider name
- **`region`**: Default region cho resources

**Multi-region:**
```hcl
provider "aws" {
  alias  = "us_west_2"
  region = "us-west-2"
}

# Use alias:
resource "aws_instance" "west" {
  provider = aws.us_west_2
  # ...
}
```

#### 2.2 DEFAULT TAGS
```hcl
default_tags {
  tags = {
    Environment = var.environment
    ManagedBy   = "Terraform"
  }
}
```
**GI·∫¢I TH√çCH:**
- T·∫•t c·∫£ resources s·∫Ω c√≥ c√°c tags n√†y
- Ti·∫øt ki·ªám th·ªùi gian, ƒë·∫£m b·∫£o consistency

**C√°c provider ph·ªï bi·∫øn:**
```hcl
# AWS
provider "aws" {
  region = "us-east-1"
}

# Azure
provider "azurerm" {
  features {}
}

# GCP
provider "google" {
  project = "my-project"
  region  = "us-central1"
}

# Kubernetes
provider "kubernetes" {
  host = "https://kubernetes-cluster:6443"
}

# Helm
provider "helm" {
  kubernetes {
    host = "https://kubernetes-cluster:6443"
  }
}
```

---

### üìù SECTION 3: VARIABLES

```hcl
variable "aws_region" {
  description = "AWS region for resources"
  type        = string
  default     = "us-east-1"

  validation {
    condition     = can(regex("^us-", var.aws_region))
    error_message = "Region must start with 'us-'."
  }
}
```

**GI·∫¢I TH√çCH:**

#### 3.1 STRING VARIABLE
```hcl
variable "aws_region" {
  description = "AWS region"
  type        = string
  default     = "us-east-1"
}
```
**GI·∫¢I TH√çCH:**
- **`description`**: Gi·∫£i th√≠ch variable
- **`type`**: Data type
- **`default`**: Gi√° tr·ªã default (optional)
- **Usage**: `var.aws_region`

#### 3.2 NUMBER VARIABLE
```hcl
variable "instance_count" {
  description = "Number of instances"
  type        = number
  default     = 2

  validation {
    condition     = var.instance_count > 0 && var.instance_count <= 10
    error_message = "Count must be between 1 and 10."
  }
}
```
**GI·∫¢I TH√çCH:**
- **`validation`**: Validate input
- **`condition`**: Boolean expression
- **`error_message`**: Error message n·∫øu fail

#### 3.3 BOOLEAN VARIABLE
```hcl
variable "enable_monitoring" {
  description = "Enable monitoring"
  type        = bool
  default     = true
}
```
**GI·∫¢I TH√çCH:**
- Boolean: true ho·∫∑c false

#### 3.4 LIST VARIABLE
```hcl
variable "availability_zones" {
  description = "List of AZs"
  type        = list(string)
  default     = ["us-east-1a", "us-east-1b", "us-east-1c"]
}
```
**GI·∫¢I TH√çCH:**
- List of strings
- **Usage:**
```hcl
azs = var.availability_zones[0]  # First element
```

#### 3.5 MAP VARIABLE
```hcl
variable "instance_types" {
  description = "Instance types by environment"
  type        = map(string)
  default = {
    dev     = "t3.micro"
    staging = "t3.small"
    prod    = "t3.medium"
  }
}
```
**GI·∫¢I TH√çCH:**
- Key-value pairs
- **Usage:**
```hcl
instance_type = var.instance_types["dev"]
# ho·∫∑c
instance_type = var.instance_types[var.environment]
```

#### 3.6 OBJECT VARIABLE
```hcl
variable "tags" {
  description = "Tags"
  type = object({
    Environment = string
    Project     = string
    Owner       = string
  })
  default = {
    Environment = "dev"
    Project     = "my-app"
    Owner       = "devops"
  }
}
```
**GI·∫¢I TH√çCH:**
- Complex nested structure
- Type validation strict

#### 3.7 OPTIONAL TYPE
```hcl
variable "cost_center" {
  type    = optional(string)
  default = null
}
```
**GI·∫¢I TH√çCH:**
- `optional`: Attribute kh√¥ng b·∫Øt bu·ªôc

**C√°ch s·ª≠ d·ª•ng variables:**
```bash
# File terraform.tfvars
aws_region = "us-east-1"
instance_count = 3

# Command line
terraform apply -var="aws_region=us-west-2"

# Environment variable
export TF_VAR_aws_region=us-west-2
terraform apply
```

---

### üìù SECTION 4: LOCALS

```hcl
locals {
  name_prefix   = "${var.project_name}-${var.environment}"
  instance_type = var.environment == "prod" ? "t3.medium" : "t3.micro"

  common_tags = {
    Environment = var.environment
    Project     = var.project_name
    ManagedBy   = "Terraform"
  }
}
```

**GI·∫¢I TH√çCH:**
- **`locals`**: Local variables
- Gi·ªëng variables nh∆∞ng:
  - Kh√¥ng ph·∫£i input parameters
  - Computed from other values
  - D√πng ƒë·ªÉ avoid repetition

**S·ª± kh√°c bi·ªát Variables vs Locals:**
```
Variables:
- Input from users
- Defined at root level
- Can be overridden (-var, .tfvars)

Locals:
- Computed within module
- Cannot be overridden
- D√πng cho derived values
```

**Examples:**
```hcl
locals {
  # Ternary operator
  instance_type = var.environment == "prod" ? "t3.medium" : "t3.micro"

  # String interpolation
  name_prefix = "${var.project}-${var.env}"

  # Complex computed values
  subnet_cidrs = {
    public  = ["10.0.1.0/24", "10.0.2.0/24"]
    private = ["10.0.10.0/24", "10.0.11.0/24"]
  }

  # Functions
  selected_azs = slice(var.availability_zones, 0, 2)
}
```

---

### üìù SECTION 5: DATA SOURCES

```hcl
data "aws_caller_identity" "current" {}
data "aws_region" "current" {}

data "aws_ami" "amazon_linux_2023" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["al2023-ami-2023.*-x86_64"]
  }
}
```

**GI·∫¢I TH√çCH:**
- **Data sources**: Fetch existing resources
- Read-only (kh√¥ng t·∫°o resources)
- **Usage:** `data.<TYPE>.<NAME>.<ATTRIBUTE>`

**Common data sources:**

#### 5.1 CALLER IDENTITY
```hcl
data "aws_caller_identity" "current" {}
```
**Usage:**
```hcl
account_id = data.aws_caller_identity.current.account_id
arn        = data.aws_caller_identity.current.arn
user_id    = data.aws_caller_identity.current.user_id
```

#### 5.2 AWS REGION
```hcl
data "aws_region" "current" {}
```
**Usage:**
```hcl
region = data.aws_region.current.name
```

#### 5.3 EXISTING VPC
```hcl
data "aws_vpc" "existing" {
  id = var.vpc_id
}
```
**Usage:**
```hcl
cidr_block = data.aws_vpc.existing.cidr_block
```

#### 5.4 LATEST AMI
```hcl
data "aws_ami" "amazon_linux_2023" {
  most_recent = true
  owners      = ["amazon"]

  filter {
    name   = "name"
    values = ["al2023-ami-2023.*-x86_64"]
  }

  filter {
    name   = "virtualization-type"
    values = ["hvm"]
  }
}
```
**GI·∫¢I TH√çCH:**
- **`most_recent`**: Get newest AMI
- **`owners`**: AMI owner
  - `amazon`: Amazon official AMIs
  - `self`: Your AMIs
- **`filter`**: Filter criteria

**Usage:**
```hcl
resource "aws_instance" "web" {
  ami = data.aws_ami.amazon_linux_2023.id
  # ...
}
```

---

### üìù SECTION 6: RESOURCES

```hcl
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true

  tags = {
    Name = "my-vpc"
  }
}
```

**GI·∫¢I TH√çCH:**
- **Resource blocks**: T·∫°o infrastructure resources
- **Syntax**: `resource "TYPE" "NAME" { ... }`
- **Usage:** `<TYPE>.<NAME>.<ATTRIBUTE>`

#### 6.1 RESOURCE EXAMPLES

**VPC:**
```hcl
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "main-vpc"
  }
}
```

**Subnet:**
```hcl
resource "aws_subnet" "public" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.1.0/24"
  availability_zone       = "us-east-1a"
  map_public_ip_on_launch = true

  tags = {
    Name = "public-subnet-1"
  }
}
```

**EC2 Instance:**
```hcl
resource "aws_instance" "web" {
  ami                    = "ami-0c55b159cbfafe1f0"
  instance_type          = "t3.micro"
  subnet_id              = aws_subnet.public.id
  vpc_security_group_ids = [aws_security_group.web.id]

  tags = {
    Name = "web-server-1"
  }
}
```

**S3 Bucket:**
```hcl
resource "aws_s3_bucket" "logs" {
  bucket = "my-app-logs"

  tags = {
    Name = "logs-bucket"
  }
}

resource "aws_s3_bucket_versioning" "logs" {
  bucket = aws_s3_bucket.logs.id

  versioning_configuration {
    status = "Enabled"
  }
}
```

**RDS Database:**
```hcl
resource "aws_db_instance" "main" {
  identifier           = "mydb"
  engine               = "mysql"
  engine_version       = "8.0"
  instance_class       = "db.t3.micro"
  allocated_storage    = 20
  storage_encrypted    = true

  db_name  = "myapp"
  username = var.db_username
  password = var.db_password

  skip_final_snapshot = true
}
```

#### 6.2 RESOURCE METADATA ARGUMENTS

**Count:**
```hcl
resource "aws_instance" "web" {
  count = 3  # Create 3 instances

  ami           = "ami-xxx"
  instance_type = "t3.micro"
}

# Access: aws_instance.web[0].id, aws_instance.web[1].id, etc.
```

**For_each:**
```hcl
resource "aws_instance" "web" {
  for_each = {
    "web-1" = "t3.micro"
    "web-2" = "t3.small"
  }

  ami           = "ami-xxx"
  instance_type = each.value

  tags = {
    Name = each.key
  }
}

# Access: aws_instance.web["web-1"].id
```

**Depends_on:**
```hcl
resource "aws_instance" "web" {
  ami           = "ami-xxx"
  instance_type = "t3.micro"

  depends_on = [aws_internet_gateway.main]
}
```

**Lifecycle:**
```hcl
resource "aws_instance" "web" {
  ami           = "ami-xxx"
  instance_type = "t3.micro"

  lifecycle {
    create_before_destroy = true
    prevent_destroy       = false
    ignore_changes        = [tags["CreatedDate"]]
  }
}
```

**Lifecycle options:**
- **`create_before_destroy`**: T·∫°o m·ªõi tr∆∞·ªõc khi x√≥a c≈©
- **`prevent_destroy`**: Kh√¥ng cho ph√©p x√≥a (critical resources)
- **`ignore_changes`**: B·ªè qua drift cho m·ªôt s·ªë attributes

---

### üìù SECTION 7: OUTPUTS

```hcl
output "vpc_id" {
  description = "ID of the VPC"
  value       = aws_vpc.main.id
}

output "instance_public_ips" {
  description = "Public IPs of instances"
  value       = aws_instance.web[*].public_ip
}

output "db_password" {
  description = "Database password"
  value       = aws_db_instance.main.password
  sensitive   = true
}
```

**GI·∫¢I TH√çCH:**
- **Outputs**: Return values sau khi `terraform apply`
- D√πng ƒë·ªÉ:
  - Display important values
  - Share gi·ªØa modules
  - Debugging

**Sensitive outputs:**
```hcl
output "db_password" {
  value     = var.db_password
  sensitive = true  # Won't show in plaintext
}
```

---

### üìù SECTION 8: MODULES

```hcl
module "vpc" {
  source = "terraform-aws-modules/vpc/aws"
  version = "5.0.0"

  name = "my-vpc"
  cidr = "10.0.0.0/16"

  azs             = ["us-east-1a", "us-east-1b"]
  private_subnets = ["10.0.1.0/24", "10.0.2.0/24"]
  public_subnets  = ["10.0.101.0/24", "10.0.102.0/24"]
}
```

**GI·∫¢I TH√çCH:**
- **Modules**: Reusable Terraform configurations
- **Benefits:**
  - Code organization
  - Reusability
  - Maintainability

**Module sources:**
```hcl
# Terraform Registry
module "vpc" {
  source = "terraform-aws-modules/vpc/aws"
  version = "5.0.0"
}

# Local path
module "database" {
  source = "./modules/database"
}

# Git repository
module "ecs" {
  source = "git::https://github.com/terraform-aws-modules/terraform-aws-ecs.git?ref=v5.0.0"
}

# S3 bucket
module "remote" {
  source = "s3::https://s3.amazonaws.com/my-bucket/terraform-module.zip"
}
```

**Module outputs:**
```hcl
# Module definition
module "vpc" {
  source = "./modules/vpc"
  # ...
}

# Use module outputs
resource "aws_subnet" "app" {
  vpc_id     = module.vpc.vpc_id
  cidr_block = "10.0.10.0/24"
}
```

---

### üìù SECTION 9: TERRAFORM FUNCTIONS

**String functions:**
```hcl
upper("hello")           # ‚Üí "HELLO"
lower("HELLO")           # ‚Üí "hello"
title("hello world")     # ‚Üí "Hello World"
replace("hello", "el", "al")  # ‚Üí "hallo"
split(",", "a,b,c")      # ‚Üí ["a", "b", "c"]
join(",", ["a", "b", "c"])  # ‚Üí "a,b,c"
format("Hello %s", "World")  # ‚Üí "Hello World"
trimspace("  hello  ")    # ‚Üí "hello"
```

**Numeric functions:**
```hcl
abs(-5)                 # ‚Üí 5
max(1, 2, 3)            # ‚Üí 3
min(1, 2, 3)            # ‚Üí 1
ceil(3.1)               # ‚Üí 4
floor(3.9)              # ‚Üí 3
pow(2, 3)               # ‚Üí 8
length(["a", "b", "c"]) # ‚Üí 3
```

**Collection functions:**
```hcl
element(["a", "b"], 0)   # ‚Üí "a"
lookup({a="1"}, "a")    # ‚Üí "1"
merge({a="1"}, {b="2"}) # ‚Üí {a="1", b="2"}
keys({a="1", b="2"})    # ‚Üí ["a", "b"]
values({a="1", b="2"})  # ‚Üí ["1", "2"]
```

**Network functions:**
```hcl
cidrhost("10.0.0.0/16", 10)     # ‚Üí "10.0.0.10"
cidrsubnet("10.0.0.0/16", 8, 1) # ‚Üí "10.1.0.0/24"
cidrnetmask("10.0.0.0/16")      # ‚Üí "255.255.0.0"
```

---

### üìù SECTION 9.5: AWS RESOURCES - COMPLETE GUIDE

#### 9.5.1 VPC (VIRTUAL PRIVATE CLOUD)

```hcl
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "main-vpc"
  }
}
```

**GI·∫¢I TH√çCH:**
- **`cidr_block`**: IP range (16 bits = 65,536 IPs)
- **`enable_dns_hostnames`**: DNS cho instances
- **`enable_dns_support`**: DNS resolution

#### 9.5.2 SUBNETS

```hcl
# Public subnets
resource "aws_subnet" "public" {
  count                   = 2
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.${count.index + 1}.0/24"
  availability_zone       = data.aws_availability_zones.available.names[count.index]
  map_public_ip_on_launch = true

  tags = { Type = "public" }
}

# Private subnets
resource "aws_subnet" "private" {
  count             = 2
  vpc_id            = aws_vpc.main.id
  cidr_block        = "10.0.10.${count.index}.0/24"
  availability_zone = data.aws_availability_zones.available.names[count.index]

  tags = { Type = "private" }
}
```

#### 9.5.3 NAT GATEWAY

```hcl
# Elastic IP
resource "aws_eip" "nat" {
  domain = "vpc"
}

# NAT Gateway
resource "aws_nat_gateway" "main" {
  allocation_id = aws_eip.nat.id
  subnet_id     = aws_subnet.public[0].id

  depends_on = [aws_internet_gateway.main]
}
```

**GI·∫¢I TH√çCH:**
- NAT Gateway cho private subnets internet access
- **Cost**: ~$0.045/hour
- **High availability**: Deploy 1 NAT Gateway per AZ

#### 9.5.4 EC2 INSTANCES

```hcl
resource "aws_instance" "web" {
  ami                    = data.aws_ami.amazon_linux_2023.id
  instance_type          = "t3.micro"
  subnet_id              = aws_subnet.public[0].id
  vpc_security_group_ids = [aws_security_group.web.id]

  root_block_device {
    volume_type = "gp3"
    volume_size = 20
    encrypted   = true
  }

  user_data = <<-EOF
    #!/bin/bash
    yum update -y
    yum install -y httpd
    systemctl start httpd
    systemctl enable httpd
  EOF

  tags = { Name = "web-server" }
}
```

#### 9.5.5 LOAD BALANCER (ALB)

```hcl
resource "aws_lb" "main" {
  name               = "my-alb"
  internal           = false
  load_balancer_type = "application"
  subnets            = aws_subnet.public[*].id

  tags = { Name = "app-alb" }
}

resource "aws_lb_target_group" "web" {
  name     = "web-tg"
  port     = 80
  protocol = "HTTP"
  vpc_id   = aws_vpc.main.id
}

resource "aws_lb_listener" "http" {
  load_balancer_arn = aws_lb.main.arn
  port              = 80
  protocol          = "HTTP"

  default_action {
    type = "forward"
    target_group_arn = aws_lb_target_group.web.arn
  }
}
```

#### 9.5.6 AUTO SCALING GROUP

```hcl
resource "aws_launch_template" "web" {
  name_prefix   = "web-"
  image_id      = data.aws_ami.amazon_linux_2023.id
  instance_type = "t3.micro"

  user_data = <<-EOF
    #!/bin/bash
    yum install -y httpd
    systemctl start httpd
  EOF
}

resource "aws_autoscaling_group" "web" {
  desired_capacity    = 2
  max_size            = 5
  min_size            = 1
  vpc_zone_identifier = aws_subnet.public[*].id

  launch_template {
    id      = aws_launch_template.web.id
    version = "$Latest"
  }
}
```

#### 9.5.7 S3 BUCKETS

```hcl
resource "aws_s3_bucket" "website" {
  bucket = "my-website"
}

resource "aws_s3_bucket_versioning" "website" {
  bucket = aws_s3_bucket.website.id
  versioning_configuration {
    status = "Enabled"
  }
}

resource "aws_s3_bucket_server_side_encryption_configuration" "website" {
  bucket = aws_s3_bucket.website.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

resource "aws_s3_bucket_public_access_block" "website" {
  bucket = aws_s3_bucket.website.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}
```

**Security Best Practices:**
- **Enable versioning**: Track object changes
- **Enable encryption**: Server-side encryption
- **Block public access**: Security by default

#### 9.5.8 RDS DATABASE

```hcl
resource "aws_db_instance" "mysql" {
  identifier           = "mydb"
  engine               = "mysql"
  engine_version       = "8.0"
  instance_class       = "db.t3.micro"
  allocated_storage    = 20

  db_name  = "myapp"
  username = "admin"
  password = var.db_password

  vpc_security_group_ids = [aws_security_group.database.id]
  db_subnet_group_name   = aws_db_subnet_group.main.name

  backup_retention_period = 30
  skip_final_snapshot     = false
}
```

#### 9.5.9 LAMBDA FUNCTIONS

```hcl
resource "aws_lambda_function" "example" {
  function_name = "my-function"
  role          = aws_iam_role.lambda.arn
  runtime       = "python3.11"
  handler       = "index.lambda_handler"

  filename         = "lambda_function.zip"
  source_code_hash = filebase64sha256("lambda_function.zip")

  environment {
    variables = {
      LOG_LEVEL = "INFO"
    }
  }
}
```

#### 9.5.10 DYNAMODB

```hcl
resource "aws_dynamodb_table" "users" {
  name         = "users"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "UserId"

  attribute {
    name = "UserId"
    type = "S"
  }

  point_in_time_recovery {
    enabled = true
  }
}
```

---

### üìù SECTION 10: TERRAFORM WORKFLOW

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    TERRAFORM WORKFLOW                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. terraform init          - Initialize working directory  ‚îÇ
‚îÇ  2. terraform validate      - Validate configuration files   ‚îÇ
‚îÇ  3. terraform fmt           - Format and check code style   ‚îÇ
‚îÇ  4. terraform plan          - Preview changes               ‚îÇ
‚îÇ  5. terraform apply         - Apply the changes             ‚îÇ
‚îÇ  6. terraform output        - Show output values            ‚îÇ
‚îÇ  7. terraform destroy       - Destroy all resources         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Chi ti·∫øt t·ª´ng l·ªánh:**

#### 10.1 TERRAFORM INIT
```bash
terraform init
```
**GI·∫¢I TH√çCH:**
- Download providers
- Initialize backend
- Download modules
- **Run m·ªói khi:**
  - Clone new repo
  - Thay ƒë·ªïi backend config
  - Th√™m/ƒë·ªïi modules

#### 10.2 TERRAFORM VALIDATE
```bash
terraform validate
```
**GI·∫¢I TH√çCH:**
- Validate syntax
- Check variable references
- **KH√îNG connect** to cloud providers

#### 10.3 TERRAFORM FMT
```bash
terraform fmt
```
**GI·∫¢I TH√çCH:**
- Format code theo HCL standard
- **Auto-format:**
```bash
terraform fmt -recursive  # Format all .tf files
terraform fmt -check      # Check if formatting needed
terraform fmt -diff       # Show formatting diff
```

#### 10.4 TERRAFORM PLAN
```bash
terraform plan
```
**GI·∫¢I TH√çCH:**
- Show execution plan
- **Show:**
  - `+` (create): New resources
  - `-` (destroy): Delete resources
  - `~` (update): Update resources
- **Options:**
```bash
terraform plan -out=tfplan       # Save plan to file
terraform plan -var="region=us-west-2"  # Override variable
```

#### 10.5 TERRAFORM APPLY
```bash
terraform apply
```
**GI·∫¢I TH√çCH:**
- Apply changes
- **Options:**
```bash
terraform apply -auto-approve    # Skip approval prompt
terraform apply tfplan           # Apply saved plan
terraform apply -var="region=us-west-2"
```

#### 10.6 TERRAFORM DESTROY
```bash
terraform destroy
```
**GI·∫¢I TH√çCH:**
- Destroy all resources
- **C·∫¢NH B√ÅO:** Kh√¥ng th·ªÉ undo!
- **Options:**
```bash
terraform destroy -auto-approve
terraform destroy -target=aws_instance.web  # Destroy specific resource
```

#### 10.7 OTHER COMMANDS
```bash
terraform output               # Show outputs
terraform show                 # Show state or resources
terraform refresh              # Update state file
terraform import               # Import existing resources
terraform state list           # List resources in state
terraform state show <resource> # Show resource details
terraform state rm <resource>  # Remove from state
terraform taint <resource>     # Mark for re-creation
terraform untaint <resource>   # Unmark resource
terraform graph                # Visualize dependency graph
terraform workspace list       # List workspaces
terraform workspace new dev    # Create workspace
```

---

### üìù SECTION 11: BEST PRACTICES

#### ‚úÖ 1. USE CONSISTENT NAMING CONVENTION
```hcl
resource "aws_instance" "web_server" { }
```
- lowercase_with_underscores cho resources
- kebab-case cho AWS resource names

#### ‚úÖ 2. ALWAYS USE VARIABLES FOR INPUTS
```hcl
variable "region" {
  type    = string
  default = "us-east-1"
}
```

#### ‚úÖ 3. USE LOCALS FOR COMPUTED VALUES
```hcl
locals {
  name_prefix = "${var.project}-${var.env}"
}
```

#### ‚úÖ 4. TAG ALL RESOURCES
```hcl
tags = {
  Environment = var.env
  Project     = var.project
  ManagedBy   = "Terraform"
}
```

#### ‚úÖ 5. USE REMOTE STATE (BACKEND)
```hcl
backend "s3" {
  bucket = "my-terraform-state"
  key    = "prod/terraform.tfstate"
  region = "us-east-1"
}
```

#### ‚úÖ 6. LOCK STATE FILE
```hcl
dynamodb_table = "terraform-locks"
```

#### ‚úÖ 7. VERSION PIN PROVIDERS
```hcl
version = "~> 5.0"
```

#### ‚úÖ 8. VALIDATE INPUTS
```hcl
validation {
  condition     = var.instance_count > 0
  error_message = "Count must be > 0"
}
```

#### ‚úÖ 9. USE MODULES FOR REUSABILITY
```hcl
module "vpc" {
  source = "./modules/vpc"
}
```

#### ‚úÖ 10. USE OUTPUTS FOR IMPORTANT VALUES
```hcl
output "vpc_id" {
  value = aws_vpc.main.id
}
```

---

### üéØ T·ªîNG K·∫æT - TERRAFORM WORKFLOW

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   TERRAFORM IaC PIPELINE                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  1. Write Terraform code (.tf files)                        ‚îÇ
‚îÇ  2. terraform init (initialize)                             ‚îÇ
‚îÇ  3. terraform validate (check syntax)                       ‚îÇ
‚îÇ  4. terraform plan (preview changes)                        ‚îÇ
‚îÇ  5. terraform apply (provision infrastructure)              ‚îÇ
‚îÇ  6. terraform output (view outputs)                         ‚îÇ
‚îÇ  7. Commit code to Git (version control)                    ‚îÇ
‚îÇ  8. Repeat for changes                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

### üìö T√ÄI LI·ªÜU THAM KH·∫¢O CHO TERRAFORM:

- **Terraform Official Docs**: https://developer.hashicorp.com/terraform/docs
- **Terraform Registry**: https://registry.terraform.io/
- **AWS Provider Docs**: https://registry.terraform.io/providers/hashicorp/aws/latest/docs
- **Terraform Modules**: https://registry.terraform.io/browse/modules

---

## ‚ö° GI·∫¢I TH√çCH ANSIBLE AWS - T·ª™ ZERO ƒê·∫æN ADVANCE

---

### üìå Ansible L√† G√¨?

**Ansible** l√† **open-source automation tool** d√πng ƒë·ªÉ:
- Configuration Management (c·∫•u h√¨nh servers)
- Application Deployment (deploy applications)
- Orchestration (ƒëi·ªÅu ph·ªëi multiple tasks)
- Provisioning AWS resources

**V√≠ d·ª• d·ªÖ hi·ªÉu:**
```
Ansible = Puppeteer cho infrastructure
- B·∫°n vi·∫øt playbooks (k·ªãch b·∫£n)
- Ansible execute tr√™n target servers
- Kh√≥ c·∫ßn c√†i ƒë·∫∑t agent tr√™n target machines
```

**Ansible vs Terraform vs Jenkins:**
| Tool | M·ª•c ƒë√≠ch | Use case |
|------|----------|----------|
| **Ansible** | Configuration management | C·∫•u h√¨nh servers, deploy apps |
| **Terraform** | Infrastructure provisioning | T·∫°o AWS resources (VPC, EC2, etc.) |
| **Jenkins** | CI/CD orchestration | Automation pipeline, build, test |

---

### üìñ C√ÅC FILE H·ªåC ANSIBLE AWS:

| File | M·ª•c ƒë√≠ch | Khi n√†o d√πng |
|------|----------|--------------|
| **learn.yaml** | Playbook ƒë·∫ßy ƒë·ªß v·ªõi comments chi ti·∫øt | H·ªçc Ansible AWS |
| **practice.yaml** | Playbook c√≥ ch·ªó tr·ªëng ƒë·ªÉ ƒëi·ªÅn | Th·ª±c h√†nh, test ki·∫øn th·ª©c |

---

### üî§ C·∫§U TR√öC C∆† B·∫¢N C·ª¶A ANSIBLE PLAYBOOK

```yaml
---
- name: "Playbook Name"
  hosts: webservers          # Target hosts
  become: true               # Sudo privilege
  vars:                      # Variables
    app_port: 8080
  tasks:                     # Tasks to execute
    - name: "Task Name"
      ansible.builtin.debug:
        msg: "Hello"
  handlers:                  # Triggered by tasks
    - name: "Restart Apache"
      ansible.builtin.service:
        name: httpd
        state: restarted
```

**Key components:**
- **hosts**: Target machines
- **vars**: Variables
- **tasks**: Operations to perform
- **handlers**: Actions on notification

---

### üìù SECTION 1: ANSIBLE BASICS

#### 1.1 PLAYBOOK STRUCTURE
```yaml
---
- name: "Section 1: Basic Playbook"
  hosts: localhost           # Ch·∫°y tr√™n local machine
  connection: local          # Local connection (kh√¥ng qua SSH)
  gather_facts: false        # Kh√¥ng thu th·∫≠p system facts
  vars:
    message: "Hello Ansible!"

  tasks:
    - name: "Print message"
      ansible.builtin.debug:
        msg: "{{ message }}"
```

**GI·∫¢I TH√çCH:**
- **`---`**: YAML document start (b·∫Øt bu·ªôc)
- **`- name`**: Play name (m·ªôt playbook c√≥ nhi·ªÅu plays)
- **`hosts`**: Target pattern
  - `localhost` ‚Üí Local machine
  - `all` ‚Üí All hosts
  - `webservers` ‚Üí Group trong inventory
- **`connection: local`**: Kh√¥ng SSH, ch·∫°y local
- **`gather_facts`**: Thu th·∫≠p system info (OS, RAM, CPU)
- **`vars`**: Define variables
- **`tasks`**: List of tasks

#### 1.2 TASKS
```yaml
tasks:
  - name: "Print OS"
    ansible.builtin.debug:
      msg: "OS: {{ ansible_distribution }}"
```

**GI·∫¢I TH√çCH:**
- **`- name`**: Task description (mandatory)
- **`ansible.builtin.debug`**: Module ƒë·ªÉ print messages
- **`{{ ansible_distribution }}`**: Jinja2 template variable

**Module naming:**
```
ansible.builtin.debug      ‚Üí Built-in module
amazon.aws.ec2_instance    ‚Üí AWS collection module
community.aws.rds_instance ‚Üí Community AWS module
```

---

### üìù SECTION 2: VARIABLES v√† FACTS

#### 2.1 VARIABLE TYPES
```yaml
vars:
  # String
  app_name: "myapp"

  # Number
  app_port: 8080

  # Boolean
  enable_ssl: true

  # List
  availability_zones:
    - us-east-1a
    - us-east-1b

  # Dictionary
  instance_config:
    type: t3.micro
    count: 2
```

**GI·∫¢I TH√çCH:**
- **String**: Text (quotes optional)
- **Number**: Integer/float
- **Boolean**: `true`/`false`
- **List**: Array (d√πng `-`)
- **Dictionary**: Key-value pairs

#### 2.2 ACCESSING VARIABLES
```yaml
- name: "Access variables"
  ansible.builtin.debug:
    msg:
      - "App: {{ app_name }}"
      - "Port: {{ app_port }}"
      - "First AZ: {{ availability_zones[0] }}"
      - "Instance type: {{ instance_config.type }}"
```

**GI·∫¢I TH√çCH:**
- **`{{ variable }}`**: Jinja2 template syntax
- **`list[0]`**: Access list element (0-indexed)
- **`dict.key`**: Access dictionary value

#### 2.3 FACTS
```yaml
- name: "Display facts"
  ansible.builtin.debug:
    msg:
      - "OS: {{ ansible_distribution }}"
      - "Architecture: {{ ansible_architecture }}"
      - "Hostname: {{ ansible_hostname }}"
```

**GI·∫¢I TH√çCH:**
- **`gather_facts: true`**: Ansible t·ª± ƒë·ªông collect facts
- **Facts l√† variables** ch·ª©a system info:
  ```
  ansible_distribution ‚Üí "Amazon Linux"
  ansible_architecture ‚Üí "x86_64"
  ansible_memtotal_mb ‚Üí 4096
  ansible_processor_vcpus ‚Üí 2
  ```

---

### üìù SECTION 3: LOOPS v√† CONDITIONS

#### 3.1 LOOPS
```yaml
- name: "Loop over list"
  ansible.builtin.debug:
    msg: "User: {{ item }}"
  loop:
    - alice
    - bob
    - charlie
```

**GI·∫¢I TH√çCH:**
- **`loop`**: Iterate over list
- **`{{ item }}`**: Current element
- **Output:**
  ```
  User: alice
  User: bob
  User: charlie
  ```

#### 3.2 LOOP WITH INDEX
```yaml
- name: "Loop with index"
  ansible.builtin.debug:
    msg: "Port {{ item.0 }} at position {{ item.1 }}"
  loop: "{{ ports | flatten(levels=1) }}"
```

**GI·∫¢I TH√çCH:**
- **`item.0`**: Port value
- **`item.1`**: Index position

#### 3.3 CONDITIONAL EXECUTION (WHEN)
```yaml
- name: "Run only in production"
  ansible.builtin.debug:
    msg: "This is production!"
  when: environment == "production"
```

**GI·∫¢I TH√çCH:**
- **`when`**: Conditional statement
- **Boolean expression**

#### 3.4 MULTIPLE CONDITIONS
```yaml
- name: "Multiple conditions"
  ansible.builtin.debug:
    msg: "All met"
  when:
    - enable_feature | default(false)
    - environment == "production"
```

**GI·∫¢I TH√çCH:**
- **AND**: List of conditions
- **`| default(false)`**: Fallback value

#### 3.5 FAILED_WHEN
```yaml
- name: "Check required var"
  ansible.builtin.debug:
    msg: "Checking"
  failed_when: required_var is not defined
```

**GI·∫¢I TH√çCH:**
- **`failed_when`**: Custom failure condition
- **`is not defined`**: Test if variable undefined

---

### üìù SECTION 4: AWS CONNECTION

#### 4.1 AWS CREDENTIALS
```yaml
environment:
  AWS_ACCESS_KEY_ID: "{{ lookup('env', 'AWS_ACCESS_KEY_ID') }}"
  AWS_SECRET_ACCESS_KEY: "{{ lookup('env', 'AWS_SECRET_ACCESS_KEY') }}"
  AWS_SESSION_TOKEN: "{{ lookup('env', 'AWS_SESSION_TOKEN') | default('') }}"
  AWS_DEFAULT_REGION: "{{ aws_region }}"
```

**GI·∫¢I TH√çCH:**
- **`lookup('env', 'VAR')`**: Read environment variable
- **Session token**: Optional (cho temporary credentials)

#### 4.2 USING AWS PROFILE
```yaml
- name: "Get caller info"
  amazon.aws.aws_caller_info:
    profile: "{{ aws_profile }}"
    region: "{{ aws_region }}"
  register: aws_info
```

**GI·∫¢I TH√çCH:**
- **`profile`**: AWS profile t·ª´ `~/.aws/credentials`
- **`register`**: Save output to variable

**~/.aws/credentials:**
```
[default]
aws_access_key_id = AKIAIOSFODNN7EXAMPLE
aws_secret_access_key = wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY
```

---

### üìù SECTION 5: EC2 INSTANCES

#### 5.1 CREATE KEY PAIR
```yaml
- name: "Create EC2 key pair"
  amazon.aws.ec2_key:
    name: "{{ key_name }}"
    region: "{{ aws_region }}"
    key_material: "{{ lookup('file', '~/.ssh/id_rsa.pub') }}"
```

**GI·∫¢I TH√çCH:**
- **`ec2_key`**: Module qu·∫£n l√Ω EC2 key pairs
- **`key_material`**: Public key content
- **`lookup('file', ...)`**: Read file from disk

#### 5.2 LAUNCH EC2 INSTANCES
```yaml
- name: "Launch EC2 instances"
  amazon.aws.ec2_instance:
    name: "web-{{ item }}{{ ansible_date_time.epoch }}"
    region: "{{ aws_region }}"
    key_name: "{{ key_name }}"
    instance_type: "{{ instance_type }}"
    image_id: "{{ ami_id }}"
    subnet_id: "{{ vpc_subnet_id }}"
    network:
      assign_public_ip: true
    user_data: |
      #!/bin/bash
      yum update -y
      yum install -y httpd
      systemctl start httpd
      echo "<h1>Hello from Ansible</h1>" > /var/www/html/index.html
    tags: "{{ tags }}"
    state: present
    count: 1
  loop: "{{ range(1, instance_count + 1) | list }}"
  register: ec2_instances
```

**GI·∫¢I TH√çCH:**
- **`name`**: Instance name (tag)
- **`instance_type`**: t3.micro, t3.small, etc.
- **`image_id`**: AMI ID
- **`user_data`**: Startup script (cloud-init)
- **`assign_public_ip: true`**: Public IP
- **`state: present`**: Create instance
- **`count`**: S·ªë instances
- **`loop`**: Create multiple instances
- **`register`**: Save result

#### 5.3 WAIT FOR INSTANCES
```yaml
- name: "Wait for instances to be running"
  amazon.aws.ec2_instance_info:
    region: "{{ aws_region }}"
    instance_ids:
      - "{{ item.instance_ids[0] }}"
  register: instance_info
  until: instance_info.instances[0].state.name == "running"
  retries: 30
  delay: 10
```

**GI·∫¢I TH√çCH:**
- **`until`**: Condition ƒë·ªÉ stop
- **`retries`**: Max attempts
- **`delay`**: Seconds gi·ªØa c√°c attempts

---

### üìù SECTION 6: VPC v√† NETWORKING

#### 6.1 CREATE VPC
```yaml
- name: "Create VPC"
  amazon.aws.ec2_vpc_net:
    name: "{{ vpc_name }}"
    cidr_block: "{{ vpc_cidr }}"
    region: "{{ aws_region }}"
    dns_hostnames: true
    dns_support: true
    tenancy: default
    state: present
  register: vpc_result
```

**GI·∫¢I TH√çCH:**
- **`cidr_block`**: IP range (e.g., 10.0.0.0/16)
- **`dns_hostnames`**: Enable DNS hostnames
- **`tenancy`**: default ho·∫∑c dedicated

**Access VPC ID:**
```yaml
"{{ vpc_result.vpc.id }}"
```

#### 6.2 INTERNET GATEWAY
```yaml
- name: "Create Internet Gateway"
  amazon.aws.ec2_vpc_igw:
    vpc_id: "{{ vpc_result.vpc.id }}"
    region: "{{ aws_region }}"
    state: present
  register: igw_result
```

**GI·∫¢I TH√çCH:**
- **`igw`**: Internet Gateway (cho public internet access)
- **Attach to VPC**

#### 6.3 SUBNETS
```yaml
- name: "Create public subnets"
  amazon.aws.ec2_vpc_subnet:
    vpc_id: "{{ vpc_result.vpc.id }}"
    region: "{{ aws_region }}"
    cidr: "{{ item.cidr }}"
    az: "{{ item.az }}"
    state: present
    tags:
      Type: public
  loop:
    - { cidr: 10.0.1.0/24, az: us-east-1a }
    - { cidr: 10.0.2.0/24, az: us-east-1b }
```

**GI·∫¢I TH√çCH:**
- **`cidr`**: Subnet CIDR (e.g., 10.0.1.0/24)
- **`az`**: Availability Zone

**Subnet types:**
- **Public**: Has route to IGW
- **Private**: No route to IGW (use NAT)
- **Database**: Isolated subnet

#### 6.4 NAT GATEWAY
```yaml
- name: "Allocate Elastic IP"
  amazon.aws.ec2_eip:
    region: "{{ aws_region }}"
    in_vpc: true
    state: present
  register: eip_nat

- name: "Create NAT Gateway"
  amazon.aws.ec2_vpc_nat_gateway:
    region: "{{ aws_region }}"
    subnet_id: "{{ public_subnet_id }}"
    eip_address: "{{ eip_nat.public_ip }}"
    state: present
```

**GI·∫¢I TH√çCH:**
- **NAT Gateway**: Cho ph√©p private subnets access internet
- **EIP**: Static IP address
- **Must be in public subnet**

#### 6.5 ROUTE TABLES
```yaml
- name: "Create public route table"
  amazon.aws.ec2_vpc_route_table:
    vpc_id: "{{ vpc_result.vpc.id }}"
    region: "{{ aws_region }}"
    tags:
      Name: public-rt
    subnets:
      - "{{ public_subnet_1 }}"
      - "{{ public_subnet_2 }}"
    routes:
      - dest: 0.0.0.0/0
        gateway_id: "{{ igw_result.gateway_id }}"
```

**GI·∫¢I TH√çCH:**
- **`dest`**: Destination CIDR (0.0.0.0/0 = all traffic)
- **`gateway_id`**: Target gateway (IGW for public, NAT for private)
- **`subnets`**: Associate subnets

---

### üìù SECTION 7: SECURITY GROUPS

```yaml
- name: "Create security group for web"
  amazon.aws.ec2_security_group:
    name: web-sg
    description: "Security group for web servers"
    vpc_id: "{{ vpc_id }}"
    region: "{{ aws_region }}"
    rules:
      - proto: tcp
        ports:
          - 80
          - 443
        cidr_ip: 0.0.0.0/0
        rule_desc: "Allow HTTP/HTTPS"
      - proto: tcp
        ports:
          - 22
        cidr_ip: 10.0.0.0/16
        rule_desc: "Allow SSH from VPC"
    tags:
      Name: web-sg
```

**GI·∫¢I TH√çCH:**
- **`rules`**: Inbound rules
- **`proto`**: Protocol (tcp, udp, icmp, -1 for all)
- **`ports`**: Port list
- **`cidr_ip`**: Source IP range
- **`rule_desc`**: Description

**Best practice:**
- Restrict SSH to specific IPs
- Use security group references instead of CIDR when possible

---

### üìù SECTION 8: S3 BUCKETS

#### 8.1 CREATE BUCKET
```yaml
- name: "Create S3 bucket"
  amazon.aws.s3_bucket:
    name: "{{ bucket_name }}"
    region: "{{ aws_region }}"
    state: present
    tags:
      Environment: dev
    encryption: AES256
    versioning: true
    public_access:
      BlockPublicAcls: true
      IgnorePublicAcls: true
```

**GI·∫¢I TH√çCH:**
- **`encryption`**: Server-side encryption
- **`versioning`**: Enable versioning (keep multiple versions)
- **`public_access`**: Security settings

#### 8.2 UPLOAD FILE
```yaml
- name: "Upload file to S3"
  amazon.aws.s3_object:
    bucket: "{{ bucket_name }}"
    region: "{{ aws_region }}"
    object: /config/app-config.yaml
    src: /tmp/app-config.yaml
    mode: put
```

**GI·∫¢I TH√çCH:**
- **`object`**: S3 key (path)
- **`src`**: Local file path
- **`mode: put`**: Upload mode

#### 8.3 DOWNLOAD FILE
```yaml
- name: "Download file from S3"
  amazon.aws.s3_object:
    bucket: "{{ bucket_name }}"
    region: "{{ aws_region }}"
    object: /config/app-config.yaml
    dest: /tmp/downloaded-config.yaml
    mode: get
```

**GI·∫¢I TH√çCH:**
- **`dest`**: Local destination
- **`mode: get`**: Download mode

#### 8.4 PRESIGNED URL
```yaml
- name: "Generate presigned URL"
  amazon.aws.s3_object:
    bucket: "{{ bucket_name }}"
    region: "{{ aws_region }}"
    object: /public/file.txt
    expiry: 3600
    mode: geturl
```

**GI·∫¢I TH√çCH:**
- **`expiry`**: Seconds until URL expires
- **`mode: geturl`**: Generate URL
- **Use case**: Share private files temporarily

---

### üìù SECTION 9: RDS DATABASES

```yaml
- name: "Create RDS MySQL instance"
  community.aws.rds_instance:
    id: "{{ db_instance_id }}"
    region: "{{ aws_region }}"
    engine: mysql
    engine_version: 8.0
    instance_class: db.t3.micro
    allocated_storage: 20
    storage_encrypted: true
    db_name: appdb
    username: admin
    password: "{{ db_password }}"
    port: 3306
    vpc_security_group_ids:
      - sg-xxxxxxxx
    publicly_accessible: false
    backup_retention_period: 7
    skip_final_snapshot: false
    state: present
```

**GI·∫¢I TH√çCH:**
- **`engine`**: mysql, postgres, etc.
- **`instance_class`**: db.t3.micro, db.t3.small, etc.
- **`storage_encrypted`**: Enable encryption
- **`publicly_accessible: false`**: Private database
- **`backup_retention_period`**: Days to keep backups

**Wait for RDS:**
```yaml
- name: "Wait for RDS to be available"
  community.aws.rds_instance_info:
    region: "{{ aws_region }}"
    db_instance_identifier: "{{ db_instance_id }}"
  register: rds_info
  until: rds_info.instances[0].db_instance_status == "available"
  retries: 60
  delay: 30
```

---

### üìù SECTION 10: LAMBDA FUNCTIONS

#### 10.1 CREATE IAM ROLE
```yaml
- name: "Create Lambda IAM role"
  amazon.aws.iam_role:
    name: lambda-role
    assume_role_policy_document:
      Version: "2012-10-17"
      Statement:
        - Effect: Allow
          Principal:
            Service: lambda.amazonaws.com
          Action: sts:AssumeRole
    managed_policies:
      - arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole
    state: present
  register: lambda_role
```

**GI·∫¢I TH√çCH:**
- **`assume_role_policy_document`**: Trust policy
- **`managed_policies`**: Attach managed policies

#### 10.2 CREATE LAMBDA FUNCTION
```yaml
- name: "Create Lambda function"
  community.aws.lambda_function:
    name: "{{ function_name }}"
    region: "{{ aws_region }}"
    state: present
    runtime: python3.11
    handler: index.lambda_handler
    timeout: 3
    memory_size: 128
    role: "{{ lambda_role.arn }}"
    zip_file: /tmp/lambda_function.zip
    environment_variables:
      ENVIRONMENT: dev
```

**GI·∫¢I TH√çCH:**
- **`runtime`**: python3.11, nodejs20.x, etc.
- **`handler`**: `filename.function_name`
- **`timeout`**: Max execution time (seconds)
- **`memory_size`**: MB (128-10240)
- **`zip_file`**: Deployment package

---

### üìù SECTION 11: AUTO SCALING GROUPS

#### 11.1 CREATE LAUNCH TEMPLATE
```yaml
- name: "Create launch template"
  amazon.aws.ec2_launch_template:
    name: "{{ lc_name }}"
    region: "{{ aws_region }}"
    image_id: "{{ ami_id }}"
    instance_type: "{{ instance_type }}"
    key_name: "{{ key_name }}"
    monitoring:
      enabled: true
    network_interfaces:
      - device_index: 0
        associate_public_ip_address: true
    state: present
  register: launch_template
```

**GI·∫¢I TH√çCH:**
- **Launch template**: Configuration cho EC2 instances in ASG
- **Reusability**: ASG uses template to launch instances

#### 11.2 CREATE ASG
```yaml
- name: "Create auto scaling group"
  amazon.aws.autoscaling_group:
    name: "{{ asg_name }}"
    region: "{{ aws_region }}"
    launch_template:
      id: "{{ launch_template.launch_template_id }}"
      version: "$Latest"
    min_size: 2
    max_size: 4
    desired_capacity: 2
    vpc_zone_identifier:
      - subnet-xxxxxxxx
      - subnet-yyyyyyyy
    health_check_period: 300
    health_check_type: ELB
    state: present
```

**GI·∫¢I TH√çCH:**
- **`min_size`**: Minimum instances
- **`max_size`**: Maximum instances
- **`desired_capacity`**: Target instances
- **`vpc_zone_identifier`**: List of subnet IDs

#### 11.3 SCALING POLICIES
```yaml
- name: "Create scale-up policy"
  amazon.aws.autoscaling_policy:
    state: present
    region: "{{ aws_region }}"
    asg_name: "{{ asg_name }}"
    name: scale-up
    adjustment_type: ChangeInCapacity
    scaling_adjustment: 1
    cooldown: 300
```

**GI·∫¢I TH√çCH:**
- **`adjustment_type`**: ChangeInCapacity, ExactCapacity, PercentChangeInCapacity
- **`scaling_adjustment`**: S·ªë instances to add/remove
- **`cooldown`**: Seconds gi·ªØa c√°c scaling actions

---

### üìù SECTION 12: CLOUDWATCH MONITORING

#### 12.1 CREATE ALARM
```yaml
- name: "Create CPU alarm"
  amazon.aws.cloudwatch_metric_alarm:
    state: present
    region: "{{ aws_region }}"
    name: "high-cpu-{{ instance_id }}"
    namespace: AWS/EC2
    metric: CPUUtilization
    statistic: Average
    period: 300
    evaluation_periods: 2
    threshold: 80.0
    comparison_operator: GreaterThanThreshold
    dimensions:
      InstanceId: "{{ instance_id }}"
```

**GI·∫¢I TH√çCH:**
- **`namespace`**: AWS/EC2, AWS/RDS, etc.
- **`metric`**: Metric name
- **`statistic`**: Average, Maximum, Minimum, Sum
- **`period`**: Seconds (300 = 5 minutes)
- **`threshold`**: Trigger value
- **`comparison_operator`**: GreaterThanThreshold, LessThanThreshold

#### 12.2 CREATE LOG GROUP
```yaml
- name: "Create log group"
  amazon.aws.cloudwatch_log_group:
    state: present
    region: "{{ aws_region }}"
    log_group_name: /ansible/app-logs
    retention: 14
```

**GI·∫¢I TH√çCH:**
- **`retention`**: Days to keep logs (1, 3, 5, 7, 14, 30, etc.)

---

### üìù SECTION 13: IAM ROLES v√† POLICIES

#### 13.1 CREATE IAM ROLE
```yaml
- name: "Create IAM role"
  amazon.aws.iam_role:
    name: "{{ role_name }}"
    assume_role_policy_document:
      Version: "2012-10-17"
      Statement:
        - Effect: Allow
          Principal:
            Service: ec2.amazonaws.com
          Action: sts:AssumeRole
    managed_policies:
      - arn:aws:iam::aws:policy/AmazonS3ReadOnlyAccess
    state: present
```

**GI·∫¢I TH√çCH:**
- **`assume_role_policy_document`**: Who can assume this role
- **`managed_policies`**: Attach AWS managed policies

#### 13.2 CREATE CUSTOM POLICY
```yaml
- name: "Create IAM policy"
  amazon.aws.iam_policy:
    policy_name: s3-access
    state: present
    policy:
      Version: "2012-10-17"
      Statement:
        - Effect: Allow
          Action:
            - s3:GetObject
            - s3:PutObject
            - s3:ListBucket
          Resource:
            - arn:aws:s3:::my-app-bucket
            - arn:aws:s3:::my-app-bucket/*
```

**GI·∫¢I TH√çCH:**
- **`Effect`**: Allow ho·∫∑c Deny
- **`Action`**: List of AWS actions
- **`Resource`**: ARN (Amazon Resource Name)

---

### üìù SECTION 14: ANSIBLE VAULT

#### 14.1 ENCRYPT SECRETS
```bash
# Create new encrypted file
ansible-vault create secrets.yaml

# Encrypt existing file
ansible-vault encrypt secrets.yaml

# View encrypted file
ansible-vault view secrets.yaml

# Edit encrypted file
ansible-vault edit secrets.yaml
```

#### 14.2 USE ENCRYPTED VARIABLES
```yaml
vars_files:
  - encrypted_secrets.yaml

tasks:
  - name: "Use encrypted password"
    ansible.builtin.debug:
      msg: "DB Password: {{ db_password }}"
    no_log: true  # Don't log sensitive data
```

**GI·∫¢I TH√çCH:**
- **`vars_files`**: Load variables from file
- **`no_log: true`**: Hide from logs

---

### üìù SECTION 15: HANDLERS

```yaml
handlers:
  - name: "Restart Apache"
    ansible.builtin.service:
      name: httpd
      state: restarted

  - name: "Reload Nginx"
    ansible.builtin.service:
      name: nginx
      state: reloaded

tasks:
  - name: "Update Apache config"
    ansible.builtin.copy:
      src: /files/httpd.conf
      dest: /etc/httpd/conf/httpd.conf
      backup: yes
    notify:
      - Restart Apache

  - name: "Force handler execution"
    ansible.builtin.meta: flush_handlers
```

**GI·∫¢I TH√çCH:**
- **`handlers`**: Definitions c·ªßa c√°c actions
- **`notify`**: Trigger handler(s) when task changes
- **`flush_handlers`**: Force execute handlers immediately

**HandlersÁâπÊÄß:**
- Ch·∫°y khi task changes (changed = true)
- Ch·∫°y 1 l·∫ßn d√π ƒë∆∞·ª£c notify nhi·ªÅu l·∫ßn
- Ch·∫°y ·ªü cu·ªëi playbook (tr·ª´ khi flush)

---

### üìù SECTION 16: ERROR HANDLING

#### 16.1 BLOCKS
```yaml
- name: "Task with error handling"
  block:
    - name: "Risky task"
      ansible.builtin.command:
        cmd: /bin/false

    - name: "This won't run"
      ansible.builtin.debug:
        msg: "Skipped"

  rescue:
    - name: "Handle error"
      ansible.builtin.debug:
        msg: "Error occurred"

  always:
    - name: "Cleanup"
      ansible.builtin.debug:
        msg: "Always runs"
```

**GI·∫¢I TH√çCH:**
- **`block`**: Main tasks
- **`rescue`**: Error handler (nh∆∞ try-catch)
- **`always`**: Cleanup (lu√¥n ch·∫°y)

#### 16.2 IGNORE ERRORS
```yaml
- name: "Task that might fail"
  ansible.builtin.command:
    cmd: /bin/true
  ignore_errors: true
  register: result

- name: "Check result"
  ansible.builtin.debug:
    msg: "Task succeeded"
  when: result is succeeded
```

**GI·∫¢I TH√çCH:**
- **`ignore_errors: true`**: Continue on failure
- **`is succeeded`**: Test if task succeeded

---

### üìù SECTION 17: TEMPLATES

#### 17.1 CREATE TEMPLATE FILE
```jinja2
# /templates/app-config.j2
application:
  name: {{ app_name }}
  port: {{ app_port }}

database:
  host: {{ db_host }}
  port: {{ db_port }}

{% if enable_ssl %}
ssl_enabled: true
{% endif %}

generated_at: {{ ansible_date_time.iso8601 }}
```

#### 17.2 DEPLOY TEMPLATE
```yaml
- name: "Create config from template"
  ansible.builtin.template:
    src: /templates/app-config.j2
    dest: /tmp/app-config.yaml
    mode: '0644'
  vars:
    config_hash: "{{ ansible_date_time.epoch | hash('md5') }}"
```

**GI·∫¢I TH√çCH:**
- **`template`**: Module ƒë·ªÉ deploy Jinja2 templates
- **`.j2`**: Jinja2 file extension
- **`| hash('md5')`**: Jinja2 filter

---

### üìù SECTION 18: PARALLEL EXECUTION

#### 18.1 SERIAL EXECUTION
```yaml
- name: "Update one at a time"
  ansible.builtin.yum:
    name: "*"
    state: latest
  serial: 1
```

**GI·∫¢I TH√çCH:**
- **`serial: 1`**: Run on 1 host at a time
- **`serial: 25%`**: Run on 25% of hosts
- **`serial: "2..4"`**: Between 2-4 hosts

#### 18.2 ASYNC TASKS
```yaml
- name: "Long running task"
  ansible.builtin.yum:
    name: docker
    state: present
  async: 600
  poll: 10
  register: yum_result

- name: "Wait for async task"
  ansible.builtin.async_status:
    jid: "{{ yum_result.ansible_job_id }}"
  register: job_result
  until: job_result.finished
  retries: 60
  delay: 10
```

**GI·∫¢I TH√çCH:**
- **`async`**: Max runtime (seconds)
- **`poll`**: Check interval (0 = fire and forget)
- **`async_status`**: Check task status

---

### üìù SECTION 19: BLUE-GREEN DEPLOYMENT

```yaml
- name: "Deploy to Green environment"
  amazon.aws.autoscaling_group:
    name: green-asg
    region: "{{ aws_region }}"
    desired_capacity: 3
    launch_template:
      id: lt-new-version
    state: present

- name: "Wait for Green to be healthy"
  ansible.builtin.pause:
    seconds: 60

- name: "Switch traffic to Green"
  community.aws.elb_classic_lb:
    name: production-lb
    region: "{{ aws_region }}"
    state: present
    instance_ids: "{{ green_instances }}"

- name: "Run smoke tests"
  ansible.builtin.uri:
    url: http://production.example.com/health
    status_code: 200
  register: smoke_test
  until: smoke_test.status == 200
  retries: 10
  delay: 5
```

**GI·∫¢I TH√çCH:**
- **Green ASG**: New version
- **Blue ASG**: Old version (kept for rollback)
- **Smoke tests**: Verify new deployment

---

### üìù SECTION 20: DYNAMIC INVENTORY

#### 20.1 CREATE INVENTORY FILE
**File: aws_ec2.yaml**
```yaml
plugin: aws_ec2
regions:
  - us-east-1
  - us-west-2
keyed_groups:
  - key: tags.Environment
    prefix: env_
  - key: tags.Application
    prefix: app_
filters:
  instance-state-name: running
compose:
  ansible_host: public_ip_address
  ansible_user: ec2-user
```

**GI·∫¢I TH√çCH:**
- **`plugin: aws_ec2`**: AWS EC2 dynamic inventory plugin
- **`keyed_groups`**: Create groups from tags
- **`filters`**: Filter instances
- **`compose`**: Set ansible variables

#### 20.2 USE DYNAMIC INVENTORY
```yaml
- name: "Use dynamic inventory"
  hosts: tag_Environment_dev
  gather_facts: true

  tasks:
    - name: "Display instance info"
      ansible.builtin.debug:
        msg:
          - "Host: {{ inventory_hostname }}"
          - "IP: {{ ansible_default_ipv4.address }}"
```

**GI·∫¢I TH√çCH:**
- **`tag_Environment_dev`**: Host group t·ª´ dynamic inventory
- Ansible t·ª± ƒë·ªông t·∫°o groups t·ª´ tags

**Run playbook:**
```bash
ansible-playbook -i aws_ec2.yaml playbook.yaml
```

---

### üìù SECTION 21: ANSIBLE ROLES

#### 21.1 ROLE STRUCTURE
```
roles/
‚îî‚îÄ‚îÄ webapp/
    ‚îú‚îÄ‚îÄ tasks/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml          # Tasks
    ‚îú‚îÄ‚îÄ handlers/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml          # Handlers
    ‚îú‚îÄ‚îÄ files/
    ‚îÇ   ‚îî‚îÄ‚îÄ config.conf       # Static files
    ‚îú‚îÄ‚îÄ templates/
    ‚îÇ   ‚îî‚îÄ‚îÄ app.conf.j2       # Templates
    ‚îú‚îÄ‚îÄ vars/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml          # Variables (high priority)
    ‚îú‚îÄ‚îÄ defaults/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml          # Default variables (low priority)
    ‚îú‚îÄ‚îÄ meta/
    ‚îÇ   ‚îî‚îÄ‚îÄ main.yml          # Role metadata
    ‚îî‚îÄ‚îÄ README.md
```

#### 21.2 USE ROLE
```yaml
- name: "Use roles"
  hosts: webservers
  become: true

  roles:
    - role: geerlingguy.apache  # External role
      vars:
        apache_listen_port: 80

    - role: ./roles/webapp     # Local role
      vars:
        app_version: 2.0.0
```

**GI·∫¢I TH√çCH:**
- **External roles**: T·ª´ Ansible Galaxy
- **Local roles**: T·ª± t·∫°o

**Install role from Galaxy:**
```bash
ansible-galaxy install geerlingguy.apache
```

---

### üìù SECTION 22: NOTIFICATIONS

#### 22.1 SLACK
```yaml
- name: "Send Slack notification"
  ansible.builtin.slack:
    token: "{{ slack_token }}"
    channel: "#ops"
    msg: |
      ‚úÖ Deployment completed!
      App: {{ app_name }}
      Version: {{ app_version }}
    username: "Ansible Bot"
    icon_emoji: ":rocket:"
    color: "good"
```

**GI·∫¢I TH√çCH:**
- **`color`**: good (green), warning (yellow), danger (red)
- **`msg`**: Message (supports multiline)

#### 22.2 EMAIL (AWS SES)
```yaml
- name: "Send email"
  community.aws.ses:
    from: "ansible@mycompany.com"
    to:
      - ops-team@mycompany.com
    subject: "Deployment Report"
    body: |
      Deployment completed successfully!
      Version: {{ app_version }}
    charset: utf-8
```

#### 22.3 MICROSOFT TEAMS
```yaml
- name: "Send to Teams"
  ansible.builtin.uri:
    url: "{{ teams_webhook }}"
    method: POST
    body_format: json
    body:
      "@type": "MessageCard"
      "@context": "https://schema.org/extensions"
      summary: "Deployment Report"
      themeColor: "0078D7"
      title: "Ansible Deployment"
      text: "Deployment completed"
    status_code: [201, 200]
```

---

### üìù SECTION 23: SECURITY HARDENING

```yaml
- name: "SSH hardening"
  become: true
  handlers:
    - name: "Restart SSH"
      ansible.builtin.service:
        name: sshd
        state: restarted

  tasks:
    - name: "Disable password authentication"
      ansible.builtin.lineinfile:
        path: /etc/ssh/sshd_config
        regexp: '^PasswordAuthentication'
        line: 'PasswordAuthentication no'
      notify: Restart SSH

    - name: "Disable root login"
      ansible.builtin.lineinfile:
        path: /etc/ssh/sshd_config
        regexp: '^PermitRootLogin'
        line: 'PermitRootLogin no'
      notify: Restart SSH

    - name: "Configure firewall"
      ansible.builtin.firewalld:
        service: "{{ item }}"
        permanent: true
        state: enabled
      loop:
        - http
        - https
        - ssh
```

**GI·∫¢I TH√çCH:**
- **`lineinfile`**: Ensure line exists in file
- **`regexp`**: Pattern to match
- **`firewalld`**: Configure firewall (RHEL/CentOS)

---

### üìù SECTION 24: BACKUP v√† RESTORE

```yaml
- name: "Create RDS snapshot"
  community.aws.rds_instance_snapshot:
    db_instance_identifier: myapp-db
    snapshot_identifier: "myapp-db-{{ ansible_date_time.iso8601 | replace(':', '-') }}"
    region: "{{ aws_region }}"
    state: present

- name: "Configure S3 lifecycle"
  amazon.aws.s3_lifecycle:
    name: my-backup-bucket
    region: "{{ aws_region }}"
    state: present
    rules:
      - id: "Archive-old-backups"
        prefix: "backups/"
        status: enabled
        transitions:
          - days: 30
            storage_class: GLACIER
          - days: 90
            storage_class: DEEP_ARCHIVE
```

**GI·∫¢I TH√çCH:**
- **Snapshot**: Point-in-time backup
- **Lifecycle policy**: Auto transition to cheaper storage

---

### üìù SECTION 25: MULTI-REGION DEPLOYMENT

```yaml
- name: "Deploy to multiple regions"
  vars:
    regions:
      - us-east-1
      - us-west-2
      - eu-west-1

  tasks:
    - name: "Deploy across regions"
      include_tasks: deploy-to-region.yaml
      loop: "{{ regions }}"
      loop_control:
        loop_var: target_region
```

**GI·∫¢I TH√çCH:**
- **`include_tasks`**: Include external task file
- **`loop_var`**: Variable name for loop item

**deploy-to-region.yaml:**
```yaml
- name: "Launch instance in {{ target_region }}"
  amazon.aws.ec2_instance:
    region: "{{ target_region }}"
    # ...
```

---

### üìù SECTION 26: PERFORMANCE TIPS

#### 26.1 FACT CACHING
**ansible.cfg:**
```ini
[defaults]
fact_caching = jsonfile
fact_caching_connection = /tmp/ansible_facts
fact_caching_timeout = 86400
```

**GI·∫¢I TH√çCH:**
- **Cache facts** ƒë·ªÉ gi·∫£m time on subsequent runs
- **TTL**: 24 hours

#### 26.2 PIPELINING
**ansible.cfg:**
```ini
[ssh_connection]
pipelining = True
```

**GI·∫¢I TH√çCH:**
- **Pipelining**: Reduce SSH connections
- **Faster execution**

#### 26.3 DELEGATION
```yaml
- name: "Run on localhost"
  ansible.builtin.command:
    cmd: docker build -t myapp .
  delegate_to: localhost
  run_once: true
```

**GI·∫¢I TH√çCH:**
- **`delegate_to`**: Run on specific host
- **`run_once`**: Execute only once

---

### üéØ ANSIBLE BEST PRACTICES

#### 1. IDempOTENCE
```yaml
# ‚ùå BAD: Not idempotent
- name: "Always restart"
  ansible.builtin.service:
    name: httpd
    state: restarted

# ‚úÖ GOOD: Idempotent
- name: "Restart only if needed"
  ansible.builtin.service:
    name: httpd
    state: started
  notify: Restart Apache
```

#### 2. USE HANDLERS
```yaml
# ‚úÖ Multiple changes ‚Üí 1 restart
- name: "Update config"
  ansible.builtin.copy:
    src: config1.conf
    dest: /etc/myapp/config1.conf
  notify: Restart App

- name: "Update another config"
  ansible.builtin.copy:
    src: config2.conf
    dest: /etc/myapp/config2.conf
  notify: Restart App
```

#### 3. VARIABLES IN FILES
```yaml
# group_vars/production.yaml
app_version: "2.0.0"
db_host: "prod-db.example.com"

# playbook.yaml
- hosts: webservers
  roles:
    - webapp
  vars_files:
    - group_vars/production.yaml
```

#### 4. USE TAGS
```yaml
- name: "Deploy app"
  hosts: webservers
  # ...

  tasks:
    - name: "Install packages"
      ansible.builtin.yum:
        name: httpd
        state: present
      tags:
        - packages

    - name: "Configure app"
      ansible.builtin.template:
        src: app.conf.j2
        dest: /etc/myapp/app.conf
      tags:
        - config
```

**Run specific tags:**
```bash
ansible-playbook playbook.yaml --tags packages
ansible-playbook playbook.yaml --skip-tags config
```

---

### üìö ANSIBLE MODULES REFERENCE

#### COMMON MODULES

**Builtin modules:**
```
ansible.builtin.debug         ‚Üí Print messages
ansible.builtin.command       ‚Üí Run commands
ansible.builtin.shell         ‚Üí Run commands in shell
ansible.builtin.copy          ‚Üí Copy files
ansible.builtin.template      ‚Üí Deploy templates
ansible.builtin.service       ‚Üí Manage services
ansible.builtin.systemd       ‚Üí Manage systemd
ansible.builtin.user          ‚Üí Manage users
ansible.builtin.lineinfile    ‚Üí Modify file lines
ansible.builtin.blockinfile   ‚Üí Add/remove blocks
ansible.builtin.file          ‚Üí Manage files/directories
ansible.builtin.uri           ‚Üí HTTP requests
ansible.builtin.slack         ‚Üí Slack notifications
```

**AWS modules (amazon.aws collection):**
```
amazon.aws.ec2_instance           ‚Üí EC2 instances
amazon.aws.ec2_vpc_net            ‚Üí VPC
amazon.aws.ec2_security_group     ‚Üí Security groups
amazon.aws.s3_bucket              ‚Üí S3 buckets
amazon.aws.s3_object              ‚Üí S3 objects
amazon.aws.iam_role               ‚Üí IAM roles
amazon.aws.iam_policy             ‚Üí IAM policies
amazon.aws.cloudwatch_metric_alarm ‚Üí CloudWatch alarms
```

**AWS modules (community.aws collection):**
```
community.aws.rds_instance        ‚Üí RDS instances
community.aws.lambda_function     ‚Üí Lambda functions
community.aws.ecs_service         ‚Üí ECS services
```

---

## üìö T√ÄI LI·ªÜU THAM KH·∫¢O:

- **Docker Docs**: https://docs.docker.com/
- **CIS Benchmark**: https://www.cisecurity.org/benchmark/docker
- **OCI Spec**: https://github.com/opencontainers/image-spec
- **Kubernetes Docs**: https://kubernetes.io/docs/
- **Seccomp**: https://docs.kernel.org/userspace-api/seccomp.html
- **AppArmor**: https://gitlab.com/apparmor/apparmor
- **Jenkins Official Docs**: https://www.jenkins.io/doc/
- **Jenkins Pipeline Syntax**: https://www.jenkins.io/doc/book/pipeline/syntax/
- **Terraform Docs**: https://developer.hashicorp.com/terraform/docs
- **Terraform Registry**: https://registry.terraform.io/

---

**FILE N√ÄY ƒê√É GI·∫¢I TH√çCH T·∫§T C·∫¢ T·ª™NG D√íNG CODE!** üéâ
